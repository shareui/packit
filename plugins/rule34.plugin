'''
–£–∂ –µ—Å–ª–∏ —Ç—ã –∏ —é–Ω—ã–π –ø–∞—Å—Ç–µ—Ä–æ–∫ , —Ç–æ —Ö–æ—Ç—è –±—ã –∏—Å—Ç–æ—á–Ω–∏–∫ —É–∫–∞–∑—ã–≤–∞–π –æ—Ç–∫—É–¥–∞ –ø–∞—Å—Ç–∏–ª :)
–í —Ç–≤–æ–µ–º —Å–ª—É—á–∞–µ: @KangelPlugins 
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ö‚†Å‚£Ä‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£†‚°¥‚†∂‚£æ‚†û‚¢Å‚£Ä‚£†‚†§‚†§‚¢§‚£Ä‚£Ä‚°Ä‚†Ä‚†Ä‚¢∞‚°ñ‚†í‚†≤‚¢¶‚£å‚°≥‚£ø‚¢•‚°Ä‚†à‚¢ª‚£∂‚°é‚†Ä‚†Ä‚¢Ä‚£¥‚†ü‚†â‚†Ä‚¢†‚°ü‚†Ä‚†Ä‚†Ä‚†Ä‚¢†‚°ü‚†Ä‚£æ‚†Ä‚†Ä
‚£¶‚£º‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£∏‚£ø‚†Ä‚†Ä‚†Ä‚¢Ä‚°§‚†ö‚†Å‚†Ä‚£º‚†Å‚°¥‚†ã‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†â‚†ô‚†≥‚¢æ‚£á‚†Ä‚°Ä‚†Ü‚£π‚£§‚°à‚†Ä‚°á‚†Ä‚†Ä‚†â‚°á‚†Ä‚¢†‚†ü‚†É‚†Ä‚†Ä‚†Ä‚¢∏‚†á‚†Ä‚†Ä‚†Ä‚†Ä‚£º‚†Å‚¢†‚°Ø‚†§‚†¥
‚†à‚†ª‚£ø‚£Ç‚£Ä‚£†‚£æ‚†ü‚¢ª‚£ø‚£∑‚£Ä‚°∂‚†ã‚†Ä‚†Ä‚†Ä‚†Ä‚£ª‚°¶‚†ì‚†Ä‚†Ä‚¢∞‚£û‚†ª‚£ç‚†ô‚†≤‚¢§‚£Ä‚†Ä‚£†‚†û‚†í‚†õ‚†â‚†Å‚†à‚†ª‚£ç‚†â‚†≥‚†§‚£§‚£á‚°¥‚†ã‚†Ä‚†Ä‚£Ä‚£§‚£∂‚¢æ‚†Ä‚†Ä‚†Ä‚†Ä‚¢∞‚°á‚†Ä‚¢∏‚£ß‚†Ä‚†Ä
‚†Ä‚†Ä‚†à‚†ª‚£ø‚†ü‚†Å‚†Ä‚†Ä‚¢ø‚£ø‚†è‚†Ä‚†Ä‚†Ä‚¢Ä‚°¥‚†ã‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ô‚¢¶‚°à‚†ì‚¢¶‚£Ä‚£à‚†ô‚†≥‚†∂‚†∂‚£∂‚£í‚°≤‚£Ü‚†Ä‚†ò‚¢ß‚°Ä‚†Ä‚†à‚¢Ø‚£†‚†∂‚£§‚£æ‚£ø‚£ø‚£ø‚¢∏‚†Ä‚†Ä‚†Ä‚†Ä‚£æ‚†Ä‚†Ä‚°ü‚£ø‚£∂‚£∂
‚†Ä‚†Ä‚†Ä‚£∞‚†è‚†Ä‚†Ä‚†Ä‚†Ä‚†∏‚°á‚†Ä‚†Ä‚†Ä‚°¥‚†ã‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ô‚†∂‚£§‚°Ä‚†â‚†ì‚†¶‚£§‚£Ä‚†Ä‚†à‚†â‚¢ª‚°Ü‚†Ä‚†Ä‚†≥‚£Ñ‚£†‚£∂‚£Ö‚£Ä‚°à‚¢ø‚£ø‚£ø‚£ø‚¢∏‚£Ä‚°Ä‚†Ä‚¢†‚°ü‚†Ä‚†Ä‚°á‚£ø‚£ø‚£ø
‚†Ä‚†Ä‚¢†‚°è‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢≥‚†Ä‚¢Ä‚°æ‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£§‚°§‚†§‚†§‚†§‚†§‚†§‚†Ω‚†∂‚¢§‚£§‚°Ñ‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Å‚†Ä‚†Ä‚†Ä‚†à‚£ø‚†Ä‚†à‚£ø‚£ø‚†ô‚£ø‚£ø‚£è‚†â‚†â‚†â‚†ì‚†æ‚¢ß‚£Ñ‚£Ä‚£ø‚£ø‚£ø‚£ø
‚†Ä‚†Ä‚¢∏‚°á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢∏‚°Ü‚£º‚†Å‚†Ä‚†Ä‚†Ä‚¢†‚†Ü‚†Ä‚£æ‚†ò‚†ß‚†§‚£Ñ‚£Ä‚£Ä‚£Ä‚£Ä‚£Ä‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£Ä‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢†‚†á‚†Ä‚†Ä‚†Ä‚°Ø‚†Ä‚†ª‚°á‚†à‚£ø‚£¶‚°Ä‚¢Ä‚†Ä‚†Ä‚†à‚†â‚†ô‚†ª‚†≠‚£Ω
‚£¢‚£Ñ‚°à‚¢ß‚†Ä‚†≥‚£Ñ‚†Ä‚†Ä‚†Ä‚†à‚£∑‚°è‚†Ä‚†Ä‚†Ä‚¢Ä‚°ü‚†Ä‚¢Ä‚°á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚†à‚†â‚†ô‚†í‚¢¶‚°¥‚†ü‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚††‚°æ‚†Ä‚†à‚££‚£¥‚†ó‚¢¶‚¢Ä‚°ø‚°Ñ‚°á‚†π‚°é‚†≤‚£ï‚¢Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†à‚†ô‚¢ø‚£Æ‚£≥‚°Ä‚†∏‚°Ü‚†Ä‚†Ä‚¢Ä‚£ª‚†É‚†Ä‚†Ä‚†Ä‚¢∏‚†É‚†Ä‚¢∏‚†Ä‚†Ä‚†Ä‚†Ä‚°Ä‚†Ä‚†Ä‚¢Ä‚£¨‚†∑‚†§‚†§‚†ñ‚†ã‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£Ä‚£§‚£§‚£¥‚°á‚†Ä‚¢∞‚£ø‚°ü‚†Ä‚£º‚¢ø‚†Å‚†Ä‚°á‚†Ä‚¢≥‚†Ä‚†à‚¢¶‚°Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚¢ô‚°ø‚¢ø‚£¶‚£ø‚†Ä‚†Ä‚£º‚¢∏‚†Ä‚†Ä‚†Ä‚†ê‚°ü‚†Ä‚†Ä‚°ü‚†Ä‚†Ä‚†Ä‚†Ä‚£ß‚†Ä‚†∞‚£è‚£Ä‚£Ä‚£Ä‚£Ä‚£Ä‚£Ä‚°§‚†§‚†ñ‚†í‚†ö‚¢π‚£ø‚†õ‚£ü‚°Ä‚¢†‚£ø‚°ø‚†Å‚£º‚£∑‚°ø‚†Ä‚¢Ä‚°ß‚†Ä‚†ò‚°Ü‚†Ä‚†Ä‚†ô‚†Ü‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚£†‚†é‚¢Ä‚°Ä‚£ø‚¢ø‚£á‚£∞‚†á‚¢∏‚†Ä‚¢∏‚†Ä‚¢∞‚†á‚†Ä‚†Ä‚°á‚†Ä‚†Ä‚†Ä‚¢†‚†ø‚£á‚¢ª‚°Ñ‚†Ä‚†Ä‚†Ä‚†ô‚¢¶‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£†‚†ü‚†â‚¢¶‚°à‚¢ª‚†õ‚†ª‚¢ß‚£¥‚£ø‚°ø‚†Å‚†Ä‚£æ‚†Å‚†Ä‚†Ä‚£∑‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚¢à‚°µ‚¢Ä‚†û‚£†‚£ø‚¢à‚£ø‚†è‚†Ä‚£è‚†Ä‚¢∏‚†Ä‚¢∏‚†Ä‚†Ä‚††‚°ß‚†§‚†§‚£Ä‚£∏‚°Ä‚†ò‚¢¶‚°ª‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ô‚¢∑‚£¶‚£Ñ‚°ò‚†Å‚†Ä‚†Ä‚†Ä‚†≥‚£¨‚£á‚†Ä‚†à‚£Ø‚†â‚†ì‚†¶‚£º‚†ã‚†Ä‚†Ä‚†Ä‚¢π‚†Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ñ‚£π‚£†‚°è‚°Ä‚¢à‚£ø‚°ø‚†Å‚†Ä‚£∏‚†è‚†Ä‚¢∏‚°Ä‚¢∏‚†Ä‚†Ä‚†Ä‚£∑‚†Ä‚†Ä‚†Ä‚¢∏‚†â‚†ô‚†¶‚¢ù‚£æ‚£¶‚£Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†â‚†≤‚¢ç‚†õ‚†≤‚¢§‚£Ä‚£Ä‚°Ω‚£ø‚°§‚†∂‚¢ø‚°Ü‚†Ä‚£†‚¢ø‚†Ä‚†Ä‚†Ä‚†Ä‚†∏‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚£∂‚†æ‚†ø‚¢¥‚£∑‚°ø‚†ã‚†Ä‚†Ä‚¢†‚£ø‚†Ä‚†Ä‚¢∏‚£á‚¢∏‚°Ñ‚†Ä‚†Ä‚°ø‚£á‚†Ä‚†Ä‚¢∏‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ô‚†ø‚£ß‚°Ä‚†Ä‚¢Ä‚¢Ä‚£§‚†¥‚†õ‚†Ä‚†Ä‚†Ä‚¢Ä‚°¥‚†ñ‚†Ä‚†Ä‚¢Ä‚£ø‚°ü‚†Å‚£∏‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†ª‚£ø‚£Ñ‚°æ‚†ã‚†Ä‚†Ä‚†Ä‚¢†‚°û‚£ª‚°Ä‚†Ä‚¢∏‚¢ª‚°Ñ‚¢≥‚°Ä‚†Ä‚¢∑‚£∏‚¢¶‚†Ä‚†∫‚£Ñ‚°Ä‚¢Ä‚£Ä‚£Ä‚†Ä‚†Ä‚†Ä‚†ô‚†ì‚†ü‚†ã‚†Å‚†Ä‚†Ä‚†Ä‚¢Ä‚°¥‚£´‚£§‚£∂‚£∂‚£ñ‚£π‚¢ø‚£ß‚†Ä‚†∏‚£Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚£†‚†û‚†ã‚†Ä‚†Ä‚†Ä‚†Ä‚¢†‚£ø‚†Ä‚†∏‚£ß‚†Ä‚¢∏‚°å‚¢∑‚°à‚¢∑‚°Ä‚†∏‚£ø‚£∑‚£∑‚£§‚¢ø‚°ø‚¢ø‚£ø‚†æ‚£ø‚£Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£æ‚°ø‚†õ‚†Å‚†Ä‚†Ä‚†Ä‚£ø‚£ø‚£ø‚°á‚†Ä‚†ô‚†õ‚¢ª‚†õ‚†õ‚£ª‚°ó‚†í‚†ö‚†õ‚†≤‚†§‚£§
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£¥‚£ø‚£ø‚£ß‚†Ä‚†π‚°Ü‚†∏‚£ß‚†à‚¢≥‚°à‚¢∑‚°Ä‚¢ø‚°ü‚¢ª‚°É‚£∏‚£ø‚†Ä‚¢ª‚°á‚†à‚†è‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†∏‚†É‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢∏‚£ø‚£ø‚£ø‚£ø‚†Ä‚†Ä‚†Ä‚¢∏‚†Ä‚¢Ä‚°è‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚¢Ä‚°¥‚†ª‚£ø‚£ø‚£ø‚£ø‚£∑‚£Ñ‚†ô‚£¶‚£ø‚£ß‚†à‚¢≥‚°Ä‚¢≥‚£ú‚£∑‚°ò‚£∑‚£Æ‚£Å‚£Ä‚£∏‚†á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢∏‚£å‚£ø‚£ü‚£ø‚†Ä‚†Ä‚¢∏‚¢∏‚†ì‚£æ‚°É‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚¢Ä‚°¥‚†ã‚†Ä‚†±‚¢Æ‚£ª‚£ø‚£ø‚£ø‚£ø‚£∂‚£å‚°π‚£ü‚£∑‚°Ñ‚†ô‚¢Æ‚°è‚†ª‚£∑‚°¨‚¢ø‚°ø‚¢ø‚°µ‚†û‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢∏‚°Ö‚†Ä‚¢ª‚£æ‚†Ä‚†Ä‚¢∏‚¢∏‚†Ä‚†à‚¢ª‚°Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚£¥‚°ø‚£¶‚°Ñ‚†Ä‚†Ä‚†Ä‚¢ª‚£ª‚£ø‚£ü‚¢ª‚†õ‚£ø‚£ª‚£ø‚£è‚¢ø‚†∂‚£Ñ‚†ô‚¢¶‚°à‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ê‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢†‚£ø‚†Ä‚†Ä‚†à‚£ø‚†Ä‚†Ä‚¢∏‚¢∏‚†Ä‚†Ä‚¢∏‚°á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚£ø‚£¶‚£æ‚£ø‚£Ü‚†Ä‚†Ä‚†Ä‚°è‚£ø‚£ø‚£∑‚£ø‚£ø‚£ø‚†ø‚£ü‚†æ‚£ß‚†à‚†ª‚£¶‚£ù‚£¶‚£Ñ‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£Ä‚£Ä‚£Ä‚£Ä‚£Ä‚£Ä‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£†‚†ü‚£ø‚£Ä‚†Ä‚†Ä‚¢∏‚†Ä‚†Ä‚£∏‚¢∏‚°Ä‚†Ä‚£∏‚†É‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†æ‚†ø‚†ø‚†ø‚£ø‚°Ñ‚†Ä‚¢Ä‚£∏‚£º‚†ø‚†ø‚¢õ‚†õ‚†Å‚†Ä‚†à‚†≥‚£ø‚£ß‚†Ä‚†ª‚£¶‚°â‚†õ‚†ø‚¢∂‚£¶‚£§‚†Ä‚†Ä‚†Ä‚£ø‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚¢ª‚°á‚†Ä‚†Ä‚£†‚£æ‚£ø‚°Ñ‚¢∏‚†∏‚°Ñ‚†Ä‚¢∏‚†Ä‚¢†‚°á‚£æ‚†Å‚¢†‚°è‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†â‚£∑‚†ú‚£©‚£•‚£§‚£à‚†õ‚¢ø‚£∑‚£Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†ª‚£ß‚†Ä‚¢ª‚°ü‚†≥‚£§‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢ø‚°Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚£º‚†É‚£†‚°æ‚†ã‚†à‚¢ø‚£∑‚†ò‚°á‚£ß‚†Ä‚£º‚¢†‚£ø‚£ß‚°ø‚†Ä‚£æ‚†É‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚¢†‚°æ‚†ó‚†ã‚†Å‚†Ä‚†Ä‚†â‚†≥‚°Ä‚†ô‚¢ø‚£∑‚£Ñ‚†Ä‚†Ä‚†Ä‚†π‚£ß‚°Ä‚¢ª‚°Ñ‚†Ä‚†â‚†ì‚¢¶‚£Ñ‚£Ä‚°Ä‚†à‚†ª‚¢¶‚£Ñ‚°¥‚†û‚£°‚°¥‚†ã‚†Ä‚†Ä‚¢†‚†Ω‚†ª‚†Ä‚†á‚¢ª‚£§‚£ü‚°ø‚£π‚£ø‚†É‚£∏‚†è‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚¢Ä‚°§‚†ö‚†â‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚¢≤‚°à‚¢ª‚£ø‚£Ü‚†Ä‚†Ä‚†Ä‚†ò‚¢∑‚°Ñ‚¢ª‚°Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†â‚†ô‚£ø‚°∂‚¢§‚£Ä‚£§‚†û‚¢π‚°á‚†Ä‚†Ä‚†Ä‚†ò‚£ª‚†ü‚†â‚¢π‚†õ‚°ø‚†ã‚¢†‚£ø‚†è‚¢†‚°ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†â‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢ø‚°Ä‚¢ô‚£ø‚£Ñ‚£Ä‚†Ä‚†Ä‚†à‚†ª‚£Ñ‚†ª‚£Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚£∞‚†ã‚†Ä‚†Ä‚†Ä‚¢Ä‚£¥‚†ü‚£ª‚°Ñ‚†Ä‚†Ä‚†Ä‚†∑‚†∂‚£∂‚£≤‚†í‚¢ª‚£†‚°ø‚†ã‚¢†‚°ü‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚°¥
‚£ì‚¢¶‚£Ä‚£Ä‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†π‚£Ü‚†ê‚£Ä‚°â‚°â‚†ë‚†Ä‚†Ä‚†à‚†≥‚£ù‚£∑‚£Ä‚£Ä‚£Ä‚£ì‚°Ä‚†Ä‚†§‚†æ‚†õ‚†Å‚¢Ä‚°ü‚£∑‚†Ä‚†à‚†Ä‚£ñ‚£æ‚†ü‚£ø‚£¶‚†à‚°ü‚†Ä‚†Ä‚†ö‚†Ä‚†Ä‚†Ä‚¢Ä‚°Ä‚¢Ä‚£Ä‚°¥‚¢Æ‚£Å‚†Ä
‚†â‚†≥‚£Ä‚†â‚†ô‚†≤‚£Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚°á‚†Ä‚†à‚†£‚°à‚†ª‚£ø‚£Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚†≥‚¢ø‚£ç‚£°‚†§‚¢§‚°Ä‚†Ä‚†Ä‚†Ä‚¢†‚°æ‚†Å‚†∏‚°á‚†Ä‚†Ä‚£ø‚°ø‚£ø‚£Ω‚¢Å‚°º‚¢ß‚°Ä‚†Ä‚†Ä‚£Ä‚†¥‚†ä‚£°‚¢∂‚†ü‚†Å‚†Ä‚†Ä‚†à‚†õ
‚†Ä‚†Ä‚†à‚¢∑‚°æ‚†õ‚†â‚°ç‚†ô‚¢Ü‚†Ä‚†Ä‚†Ä‚¢†‚†á‚†Ä‚†Ä‚†Ä‚†ô‚¢¶‚°à‚†ø‚£ø‚£Ñ‚°Ä‚†Ä‚¢Ä‚°§‚†æ‚†ã‚†Ä‚£Ñ‚†Ä‚†ô‚¢∂‚°í‚†æ‚†ã‚†Ä‚†Ä‚†Ä‚°á‚†Ä‚†Ä‚¢†‚¢É‚£ø‚°Ω‚†ã‚†Ä‚†Ä‚¢ª‚†Ä‚¢ö‚°•‚£æ‚£ø‚£¥‚°ã‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†ô‚†õ‚†∂‚£ß‚†Ä‚†ò‚°∑‚¢∂‚£∂‚£º‚£§‚£§‚°Ä‚†Ä‚†Ä‚†Ä‚†±‚£§‚£∏‚†ø‚†ø‚†õ‚†â‚†Ä‚†Ä‚£†‚†æ‚†Ω‚†∑‚¢¶‚£Ä‚†ô‚°Ü‚†Ä‚†Ä‚†Ä‚†Ä‚£á‚£¥‚£∂‚¢è‚£æ‚†ü‚†Ä‚†Ä‚†Ä‚†Ä‚¢∏‚†û‚£ø‚£ø‚†ü‚°è‚†â‚°ø‚£∑‚£¶‚£Ñ‚£Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£º‚†É‚†Ä‚†Ä‚°á‚¢∏‚†õ‚°á‚†∏‚¢ª‚†â‚°∑‚†ñ‚†í‚†ö‚†â‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†º‚†É‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚†â‚†â‚†ì‚†∫‚†∂‚†¶‚£ø‚°ü‚¢°‚°û‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢∏‚†Ä‚°á‚£æ‚°Ñ‚†á‚†Ä‚°á‚†Ä‚†ù‚†ø‚£æ‚£ø‚°ó
‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚°æ‚†Å‚†Ä‚†Ä‚¢Ä‚°á‚¢∏‚†Ä‚°¨‚¢§‚†à‚°Ñ‚°á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚†â‚†â‚†â‚†â‚†ô‚†í‚†í‚†í‚†í‚†í‚¢õ‚£∂‚†ã‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢∏‚†Ä‚°á‚°ø‚£Ñ‚£Ω‚°†‚°á‚†Ä‚°Ü‚°û‚£õ‚†Å‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£∏‚¢Å‚°á‚°∏‚¢Å‚£è‚°º‚†Ä‚°á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†§‚†Ñ‚°Ä‚†Ä‚†Ä‚†â‚†â‚†â‚†ô‚†í‚†í‚†í‚¢í‚£í‚£í‚°∂‚£∂‚£ä‚°á‚¢Ä‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†∏‚°Ü‚£á‚°ø‚£ø‚£ø‚£á‚£ß‚£æ‚£∑‚°ù‚¢∂‚†Ä‚†Ä
If you're a young 'paster', you should at least mention the source you pasted from :)
In your case: @KangelPlugins 
'''


import random
import requests
import threading
import random
import os
import time
import concurrent.futures
from ui.settings import Header, Switch, Divider, Input, Selector, Text
from base_plugin import BasePlugin, HookResult, HookStrategy
from client_utils import send_message, get_send_messages_helper
from android_utils import log
from org.telegram.messenger import ApplicationLoader
from markdown_utils import parse_markdown
from ui.bulletin import BulletinHelper
from typing import List, Dict, Tuple
import json
import uuid
import mimetypes

__id__ = "rule34_search"
__name__ = "BooruSearch"
__version__ = "1.8.0"
__description__ = """
–ü–ª–∞–≥–∏–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ Booru-based —Å–∞–π—Ç–∞—Ö.

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:
- rule34.xxx
- yande.re
- danbooru.donmai.us
- safebooru.org
- gelbooru.com
- konachan.com

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
- .r34/yandere/danbooru/safebooru/gelbooru/konachan/random [—Ç–µ–≥–∏] (–∫–æ–ª-–≤–æ)
"""
__author__ = "@ArThirtyFour | @KangelPlugins"
__min_version__ = "11.12.1"
__icon__ = "Sayanoutaaaa/7"

class Locales:
    default = {
        "tags_in_header": "Tags (include)",
        "tags_in_text": "Tags",
        "tags_in_subtext": 'Enter through space. Example: tag1 tag2. Leave " " for empty.',
        "tags_ex_header": "Tags (exclude)",
        "tags_ex_text": "Tags",
        "tags_ex_subtext": 'Enter through ;. Example: tag1; tag2. Leave " " for empty.',
        "antiai_text": "Anti-AI",
        "antiai_subtext": "AI-generated content filter",
        "usage_divider": "Usage: .r34.",
        "not_found": "Nothing found!",
        "not_found_filtered": "Nothing found after filtering!",
        "request_error": "Request error: {e}",
        "xml_parse_error": "XML parse error.",
        "general_data_error": "An general error occurred while fetching data: {e}",
        "unknown_site": "Unknown search site.",
        "no_args": "No arguments!",
        "usage": "Usage: .r34 [tag]\nExample: .r34 anime",
        "searching": "Searching...",
        "unexpected_url_error": "An unexpected error occurred while getting the URL.",
        "settings_output_header": "Output Display Settings",
        "show_requested_tags_text": "Show requested tags",
        "show_requested_tags_subtext": "Show tags you entered in the query",
        "show_post_tags_text": "Show tags in post",
        "show_post_tags_subtext": "Show all tags of the found post",
        "show_image_link_text": "Show image link",
        "show_image_link_subtext": "Show direct link to the image",
        "post_found_header": "üîû *Post found!*\n\n",
        "requested_tags_line": "üîç *Requested tags:* `{requested_tags_str}`\n\n",
        "post_tags_line": "üè∑Ô∏è *Tags in post:* `{post_tags}`\n\n",
        "rating_line": "üîû *Rating:* `{rating}`\n\n",
        "image_link_line": "üîó *Link:* [Open image]({image_url})",
        "search_thread_error": "An error occurred in the search thread: {e}",
        "posts_count_header": "Posts Count",
        "posts_count_text": "Number of posts to search",
        "posts_count_subtext": "Max: 1000",
        "theme_header": "Theme",
        "theme_text": "Choose caption theme",
        "theme_item_normal": "Normal",
        "theme_item_nso": "Needy Streamer Overload",
        "emoji_header_normal": "[‚ù§Ô∏è](5278611606756942667)",
        "emoji_req_normal": "[üîç](5276395476646653290)",
        "emoji_tags_normal": "[üìö](5206626000665868017)",
        "emoji_link_normal": "[üîó](5278305362703835500)",
        "emoji_header_nso": "[‚ù§Ô∏è](5366601141461205169)",
        "emoji_req_nso": "[üåê](5264949504766921879)",
        "emoji_tags_nso": "[üîÇ](5264951944308343923)",
        "emoji_link_nso": "[üìù](5267392860122006833)",
        "proxy_settings_header": "Proxy Settings",
        "use_proxy_text": "Use proxy",
        "use_proxy_subtext": "Automatically use proxy if site is blocked",
        "update_proxies_text": "Update proxy list",
        "update_proxies_subtext": "Download and check fresh proxy list",
        "proxy_update_started": "Proxy update started...",
        "show_requested_tags_text": "Show requested tags",
        "show_requested_tags_subtext": "Show tags you entered in the query",
        "show_post_tags_text": "Show tags in post",
        "show_post_tags_subtext": "Show all tags of the found post",
        "show_image_link_text": "Show image link",
        "show_image_link_subtext": "Show direct link to the image",
        "settings_output_header": "Output Display Settings",
        "send_count_header": "Send Count",
        "send_count_text": "How many posts to send",
        "send_count_subtext": "Max: 10. Can also be set at the end of the command, e.g. .r34 anime 2",
        "yandere_header": "Yande.re Settings",
        "yandere_tags_in_header": "Yande.re Tags (include)",
        "yandere_tags_in_text": "Tags",
        "yandere_tags_in_subtext": 'Enter through space. Example: tag1 tag2. Leave " " for empty.',
        "yandere_tags_ex_header": "Yande.re Tags (exclude)",
        "yandere_tags_ex_text": "Tags",
        "yandere_tags_ex_subtext": 'Enter through ;. Example: tag1; tag2. Leave " " for empty.',
        "yandere_posts_count_header": "Yande.re Posts Count",
        "yandere_posts_count_text": "Number of posts to search",
        "yandere_posts_count_subtext": "Max: 200",
        "yandere_send_count_header": "Yande.re Send Count",
        "yandere_send_count_text": "How many posts to send",
        "yandere_send_count_subtext": "Max: 10. Can be set at the end of the command",
        "yandere_rating_header": "Yande.re Rating Filter",
        "yandere_rating_text": "Rating",
        "yandere_rating_subtext": "Options: safe, questionable, explicit. Leave empty for all",
        "danbooru_header": "Danbooru Settings",
        "danbooru_tags_in_header": "Danbooru Tags (include)",
        "danbooru_tags_in_text": "Tags",
        "danbooru_tags_in_subtext": 'Enter through space. Example: tag1 tag2. Leave " " for empty.',
        "danbooru_tags_ex_header": "Danbooru Tags (exclude)",
        "danbooru_tags_ex_text": "Tags",
        "danbooru_tags_ex_subtext": 'Enter through ;. Example: tag1; tag2. Leave " " for empty.',
        "danbooru_posts_count_header": "Danbooru Posts Count",
        "danbooru_posts_count_text": "Number of posts to search",
        "danbooru_posts_count_subtext": "Max: 200",
        "danbooru_send_count_header": "Danbooru Send Count",
        "danbooru_send_count_text": "How many posts to send",
        "danbooru_send_count_subtext": "Max: 10. Can be set at the end of the command",
        "danbooru_rating_header": "Danbooru Rating Filter",
        "danbooru_rating_text": "Rating",
        "danbooru_rating_subtext": "Options: general, sensitive, questionable, explicit. Leave empty for all",
        "safebooru_header": "Safebooru Settings",
        "safebooru_tags_in_header": "Safebooru Tags (include)",
        "safebooru_tags_in_text": "Tags",
        "safebooru_tags_in_subtext": 'Enter through space. Example: tag1 tag2. Leave " " for empty.',
        "safebooru_tags_ex_header": "Safebooru Tags (exclude)",
        "safebooru_tags_ex_text": "Tags",
        "safebooru_tags_ex_subtext": 'Enter through ;. Example: tag1; tag2. Leave " " for empty.',
        "safebooru_posts_count_header": "Safebooru Posts Count",
        "safebooru_posts_count_text": "Number of posts to search",
        "safebooru_posts_count_subtext": "Max: 200",
        "safebooru_send_count_header": "Safebooru Send Count",
        "safebooru_send_count_text": "How many posts to send",
        "safebooru_send_count_subtext": "Max: 10. Can be set at the end of the command",
        "proxy_rotate_text": "Rotate proxies",
        "proxy_rotate_subtext": "Automatically rotate proxy for each request",
        "proxy_user_agent_text": "Rotate User-Agent",
        "proxy_user_agent_subtext": "Change User-Agent to avoid detection",
        "gelbooru_header": "Gelbooru Settings",
        "gelbooru_tags_in_header": "Gelbooru Tags (include)",
        "gelbooru_tags_in_text": "Tags",
        "gelbooru_tags_in_subtext": 'Enter through space. Example: tag1 tag2. Leave " " for empty.',
        "gelbooru_tags_ex_header": "Gelbooru Tags (exclude)",
        "gelbooru_tags_ex_text": "Tags",
        "gelbooru_tags_ex_subtext": 'Enter through ;. Example: tag1; tag2. Leave " " for empty.',
        "gelbooru_posts_count_header": "Gelbooru Posts Count",
        "gelbooru_posts_count_text": "Number of posts to search",
        "gelbooru_posts_count_subtext": "Max: 100",
        "gelbooru_send_count_header": "Gelbooru Send Count",
        "gelbooru_send_count_text": "How many posts to send",
        "gelbooru_send_count_subtext": "Max: 10. Can be set at the end of the command",
        "konachan_header": "Konachan Settings",
        "konachan_tags_in_header": "Konachan Tags (include)",
        "konachan_tags_in_text": "Tags",
        "konachan_tags_in_subtext": 'Enter through space. Example: tag1 tag2. Leave " " for empty.',
        "konachan_tags_ex_header": "Konachan Tags (exclude)",
        "konachan_tags_ex_text": "Tags",
        "konachan_tags_ex_subtext": 'Enter through ;. Example: tag1; tag2. Leave " " for empty.',
        "konachan_posts_count_header": "Konachan Posts Count",
        "konachan_posts_count_text": "Number of posts to search",
        "konachan_posts_count_subtext": "Max: 100",
        "konachan_send_count_header": "Konachan Send Count",
        "konachan_send_count_text": "How many posts to send",
        "konachan_send_count_subtext": "Max: 10. Can be set at the end of the command",
        "random_command_header": "Random Search",
        "random_command_text": "Search across all sources",
        "random_command_subtext": "Usage: .random [tags] [count]",
        "stop_on_not_found": "Stop if not found",
        "stop_on_not_found_subtext": "Don't search further if nothing found in first attempt",
    }
    en = default
    ru = {
        "tags_in_header": "–¢–µ–≥–∏ (–≤–∫–ª—é—á–∞—é—â–∏–µ)",
        "tags_in_text": "–¢–µ–≥–∏",
        "tags_in_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª. –ü—Ä–∏–º–µ—Ä: tag1 tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "tags_ex_header": "–¢–µ–≥–∏ (–∏—Å–∫–ª—é—á–∞—é—â–∏–µ)",
        "tags_ex_text": "–¢–µ–≥–∏",
        "tags_ex_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ ;. –ü—Ä–∏–º–µ—Ä: tag1; tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "antiai_text": "–ê–Ω—Ç–∏-–ò–ò",
        "antiai_subtext": "–§–∏–ª—å—Ç—Ä —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ò–ò –∫–æ–Ω—Ç–µ–Ω—Ç–∞",
        "usage_divider": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: .r34.",
        "not_found": "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!",
        "not_found_filtered": "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏!",
        "request_error": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}",
        "xml_parse_error": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ XML.",
        "general_data_error": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}",
        "unknown_site": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å–∞–π—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞.",
        "no_args": "–ù–µ—Ç –∞–≥—Ä—É–º–µ–Ω—Ç–æ–≤!",
        "usage": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: .r34 [—Ç–µ–≥–∏] [–∫–æ–ª-–≤–æ] [-–∏—Å–∫–ª—é—á–µ–Ω–∏–µ]\n–ü—Ä–∏–º–µ—Ä: .r34 anime 2 -ai_generated",
        "searching": "–ò—â–µ–º...",
        "unexpected_url_error": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ URL.",
        "post_found_header": "üîû *–ù–∞–π–¥–µ–Ω –ø–æ—Å—Ç!*\n\n",
        "requested_tags_line": "üîç *–ó–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–µ —Ç–µ–≥–∏:* `{requested_tags_str}`\n\n",
        "post_tags_line": "üè∑Ô∏è *–¢–µ–≥–∏ –≤ –ø–æ—Å—Ç–µ:* `{post_tags}`\n\n",
        "rating_line": "üîû *–†–µ–π—Ç–∏–Ω–≥:* `{rating}`\n\n",
        "image_link_line": "üîó *–°—Å—ã–ª–∫–∞:* [–û—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ]({image_url})",
        "search_thread_error": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ –ø–æ–∏—Å–∫–∞: {e}",
        "posts_count_header": "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤",
        "posts_count_text": "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞",
        "posts_count_subtext": "–ú–∞–∫—Å–∏–º—É–º: 1000",
        "send_count_header": "–°–∫–æ–ª—å–∫–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å",
        "send_count_text": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å",
        "send_count_subtext": "–ú–∞–∫—Å–∏–º—É–º: 10. –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –≤ –∫–æ–Ω—Ü–µ –∫–æ–º–∞–Ω–¥—ã, –Ω–∞–ø—Ä. .r34 anime 2",
        "theme_header": "–¢–µ–º–∞ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è",
        "theme_text": "–í—ã–±–æ—Ä —Ç–µ–º—ã –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –ø–æ–¥–ø–∏—Å–∏",
        "theme_item_normal": "–û–±—ã—á–Ω–∞—è",
        "theme_item_nso": "Needy Streamer Overload",
        "emoji_header_normal": "[‚ù§Ô∏è](5278611606756942667)",
        "emoji_req_normal": "[üîç](5276395476646653290)",
        "emoji_tags_normal": "[üìö](5206626000665868017)",
        "emoji_link_normal": "[üîó](5278305362703835500)",
        "emoji_header_nso": "[‚ù§Ô∏è](5366601141461205169)",
        "emoji_req_nso": "[üåê](5264949504766921879)",
        "emoji_tags_nso": "[üîÇ](5264951944308343923)",
        "emoji_link_nso": "[üìù](5267392860122006833)",
        "proxy_settings_header": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∫—Å–∏",
        "use_proxy_text": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ–∫—Å–∏",
        "use_proxy_subtext": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ–∫—Å–∏ –µ—Å–ª–∏ —Å–∞–π—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω",
        "update_proxies_text": "–û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏",
        "update_proxies_subtext": "–ó–∞–≥—Ä—É–∑–∏—Ç—å –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–≤–µ–∂–∏–π —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏",
        "proxy_update_started": "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–∫—Å–∏ –Ω–∞—á–∞–ª–æ—Å—å...",
        "show_requested_tags_text": "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–µ —Ç–µ–≥–∏",
        "show_requested_tags_subtext": "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ç–µ–≥–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –≤–≤–µ–ª–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ",
        "show_post_tags_text": "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ç–µ–≥–∏ –≤ –ø–æ—Å—Ç–µ",
        "show_post_tags_subtext": "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –≤—Å–µ —Ç–µ–≥–∏ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –ø–æ—Å—Ç–∞",
        "show_image_link_text": "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
        "show_image_link_subtext": "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
        "settings_output_header": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤—ã–≤–æ–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞",
        "proxy_update_success": "–°–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏ –æ–±–Ω–æ–≤–ª–µ–Ω! –ù–∞–π–¥–µ–Ω–æ {count} —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ–∫—Å–∏",
        "proxy_update_error": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –ø—Ä–æ–∫—Å–∏: {error}",
        "no_working_proxies": "–†–∞–±–æ—á–∏–µ –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã",
        "yandere_header": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ Yande.re",
        "yandere_tags_in_header": "Yande.re —Ç–µ–≥–∏ (–≤–∫–ª—é—á–∞—é—â–∏–µ)",
        "yandere_tags_in_text": "–¢–µ–≥–∏",
        "yandere_tags_in_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª. –ü—Ä–∏–º–µ—Ä: tag1 tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "yandere_tags_ex_header": "Yande.re —Ç–µ–≥–∏ (–∏—Å–∫–ª—é—á–∞—é—â–∏–µ)",
        "yandere_tags_ex_text": "–¢–µ–≥–∏",
        "yandere_tags_ex_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ ;. –ü—Ä–∏–º–µ—Ä: tag1; tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "yandere_posts_count_header": "Yande.re –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤",
        "yandere_posts_count_text": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –∏—Å–∫–∞—Ç—å",
        "yandere_posts_count_subtext": "–ú–∞–∫—Å: 200",
        "yandere_send_count_header": "Yande.re —Å–∫–æ–ª—å–∫–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å",
        "yandere_send_count_text": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å",
        "yandere_send_count_subtext": "–ú–∞–∫—Å: 10. –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –≤ –∫–æ–Ω—Ü–µ –∫–æ–º–∞–Ω–¥—ã",
        "yandere_rating_header": "Yande.re —Ñ–∏–ª—å—Ç—Ä —Ä–µ–π—Ç–∏–Ω–≥–∞",
        "yandere_rating_text": "–†–µ–π—Ç–∏–Ω–≥",
        "yandere_rating_subtext": "–í–∞—Ä–∏–∞–Ω—Ç—ã: safe, questionable, explicit. –ü—É—Å—Ç–æ = –≤—Å–µ",
        "danbooru_header": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ Danbooru",
        "danbooru_tags_in_header": "Danbooru —Ç–µ–≥–∏ (–≤–∫–ª—é—á–∞—é—â–∏–µ)",
        "danbooru_tags_in_text": "–¢–µ–≥–∏",
        "danbooru_tags_in_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª. –ü—Ä–∏–º–µ—Ä: tag1 tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "danbooru_tags_ex_header": "Danbooru —Ç–µ–≥–∏ (–∏—Å–∫–ª—é—á–∞—é—â–∏–µ)",
        "danbooru_tags_ex_text": "–¢–µ–≥–∏",
        "danbooru_tags_ex_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ ;. –ü—Ä–∏–º–µ—Ä: tag1; tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "danbooru_posts_count_header": "Danbooru –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤",
        "danbooru_posts_count_text": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –∏—Å–∫–∞—Ç—å",
        "danbooru_posts_count_subtext": "–ú–∞–∫—Å: 200",
        "danbooru_send_count_header": "Danbooru —Å–∫–æ–ª—å–∫–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å",
        "danbooru_send_count_text": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å",
        "danbooru_send_count_subtext": "–ú–∞–∫—Å: 10. –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –≤ –∫–æ–Ω—Ü–µ –∫–æ–º–∞–Ω–¥—ã",
        "danbooru_rating_header": "Danbooru —Ñ–∏–ª—å—Ç—Ä —Ä–µ–π—Ç–∏–Ω–≥–∞",
        "danbooru_rating_text": "–†–µ–π—Ç–∏–Ω–≥",
        "danbooru_rating_subtext": "–í–∞—Ä–∏–∞–Ω—Ç—ã: general, sensitive, questionable, explicit. –ü—É—Å—Ç–æ = –≤—Å–µ",
        "safebooru_header": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ Safebooru",
        "safebooru_tags_in_header": "Safebooru —Ç–µ–≥–∏ (–≤–∫–ª—é—á–∞—é—â–∏–µ)",
        "safebooru_tags_in_text": "–¢–µ–≥–∏",
        "safebooru_tags_in_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª. –ü—Ä–∏–º–µ—Ä: tag1 tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "safebooru_tags_ex_header": "Safebooru —Ç–µ–≥–∏ (–∏—Å–∫–ª—é—á–∞—é—â–∏–µ)",
        "safebooru_tags_ex_text": "–¢–µ–≥–∏",
        "safebooru_tags_ex_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ ;. –ü—Ä–∏–º–µ—Ä: tag1; tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "safebooru_posts_count_header": "Safebooru –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤",
        "safebooru_posts_count_text": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –∏—Å–∫–∞—Ç—å",
        "safebooru_posts_count_subtext": "–ú–∞–∫—Å: 200",
        "safebooru_send_count_header": "Safebooru —Å–∫–æ–ª—å–∫–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å",
        "safebooru_send_count_text": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å",
        "safebooru_send_count_subtext": "–ú–∞–∫—Å: 10. –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –≤ –∫–æ–Ω—Ü–µ –∫–æ–º–∞–Ω–¥—ã",
        "proxy_rotate_text": "–†–æ—Ç–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∫—Å–∏",
        "proxy_rotate_subtext": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –º–µ–Ω—è—Ç—å –ø—Ä–æ–∫—Å–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞",
        "proxy_user_agent_text": "–†–æ—Ç–∏—Ä–æ–≤–∞—Ç—å User-Agent",
        "proxy_user_agent_subtext": "–ú–µ–Ω—è—Ç—å User-Agent –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è",
        "gelbooru_header": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ Gelbooru",
        "gelbooru_tags_in_header": "Gelbooru —Ç–µ–≥–∏ (–≤–∫–ª—é—á–∞—é—â–∏–µ)",
        "gelbooru_tags_in_text": "–¢–µ–≥–∏",
        "gelbooru_tags_in_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª. –ü—Ä–∏–º–µ—Ä: tag1 tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "gelbooru_tags_ex_header": "Gelbooru —Ç–µ–≥–∏ (–∏—Å–∫–ª—é—á–∞—é—â–∏–µ)",
        "gelbooru_tags_ex_text": "–¢–µ–≥–∏",
        "gelbooru_tags_ex_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ ;. –ü—Ä–∏–º–µ—Ä: tag1; tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "gelbooru_posts_count_header": "Gelbooru –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤",
        "gelbooru_posts_count_text": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –∏—Å–∫–∞—Ç—å",
        "gelbooru_posts_count_subtext": "–ú–∞–∫—Å: 100",
        "gelbooru_send_count_header": "Gelbooru —Å–∫–æ–ª—å–∫–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å",
        "gelbooru_send_count_text": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å",
        "gelbooru_send_count_subtext": "–ú–∞–∫—Å: 10. –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –≤ –∫–æ–Ω—Ü–µ –∫–æ–º–∞–Ω–¥—ã",
        "konachan_header": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ Konachan",
        "konachan_tags_in_header": "Konachan —Ç–µ–≥–∏ (–≤–∫–ª—é—á–∞—é—â–∏–µ)",
        "konachan_tags_in_text": "–¢–µ–≥–∏",
        "konachan_tags_in_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª. –ü—Ä–∏–º–µ—Ä: tag1 tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "konachan_tags_ex_header": "Konachan —Ç–µ–≥–∏ (–∏—Å–∫–ª—é—á–∞—é—â–∏–µ)",
        "konachan_tags_ex_text": "–¢–µ–≥–∏",
        "konachan_tags_ex_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ ;. –ü—Ä–∏–º–µ—Ä: tag1; tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "konachan_posts_count_header": "Konachan –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤",
        "konachan_posts_count_text": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –∏—Å–∫–∞—Ç—å",
        "konachan_posts_count_subtext": "–ú–∞–∫—Å: 100",
        "konachan_send_count_header": "Konachan —Å–∫–æ–ª—å–∫–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å",
        "konachan_send_count_text": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å",
        "konachan_send_count_subtext": "–ú–∞–∫—Å: 10. –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –≤ –∫–æ–Ω—Ü–µ –∫–æ–º–∞–Ω–¥—ã",
        "random_command_header": "–°–ª—É—á–∞–π–Ω—ã–π –ø–æ–∏—Å–∫",
        "random_command_text": "–ü–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º",
        "random_command_subtext": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: .random [—Ç–µ–≥–∏] [–∫–æ–ª-–≤–æ]",
        "stop_on_not_found": "–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ",
        "stop_on_not_found_subtext": "–ù–µ –∏—Å–∫–∞—Ç—å –¥–∞–ª—å—à–µ –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –ø–µ—Ä–≤—ã–π —Ä–∞–∑",
    }

def localise(key: str) -> str:
    from java.util import Locale
    lang = Locale.getDefault().getLanguage()
    locale_dict = getattr(Locales, lang, Locales.default)
    return locale_dict.get(key, key)

def localise_rating(rating_code: str, source: str = 'yandere') -> str:
    try:
        from java.util import Locale
        lang = Locale.getDefault().getLanguage()
    except Exception:
        lang = "ru"
    
    if source == 'yandere':
        if lang.startswith("ru"):
            rating_map = {'s': '–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π', 'q': '–°–æ–º–Ω–∏—Ç–µ–ª—å–Ω—ã–π', 'e': '–û—Ç–∫—Ä–æ–≤–µ–Ω–Ω—ã–π'}
        else:
            rating_map = {'s': 'Safe', 'q': 'Questionable', 'e': 'Explicit'}
    else:
        if lang.startswith("ru"):
            rating_map = {'g': '–û–±—â–∏–π', 's': '–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π', 'q': '–°–æ–º–Ω–∏—Ç–µ–ª—å–Ω—ã–π', 'e': '–û—Ç–∫—Ä–æ–≤–µ–Ω–Ω—ã–π'}
        else:
            rating_map = {'g': 'General', 's': 'Sensitive', 'q': 'Questionable', 'e': 'Explicit'}
    
    return rating_map.get(rating_code, rating_code)

# User-Agent —Å–ø–∏—Å–æ–∫ –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15",
    "Mozilla/5.0 (X11; Linux x86_64; rv:121.0) Gecko/20100101 Firefox/121.0",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0",
]

def get_random_user_agent() -> str:
    return random.choice(USER_AGENTS)

def get_proxy_list_from_url(url: str) -> List[str]:
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        
        raw_proxies = [line.strip() for line in response.text.split('\n') if line.strip()]
        
        proxies = []
        for proxy in raw_proxies:
            if proxy.startswith('http://') or proxy.startswith('https://'):
                proxy = proxy.replace('http://', '').replace('https://', '')
            elif proxy.startswith('socks4://') or proxy.startswith('socks5://'):
                proxy = proxy.replace('socks4://', '').replace('socks5://', '')
            
            if ':' in proxy:
                proxies.append(proxy)
        
        log(f"[BooruSearch] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(proxies)} –ø—Ä–æ–∫—Å–∏")
        return proxies
    except Exception as e:
        log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–∫—Å–∏: {e}")
        return []

def check_single_proxy(proxy: str) -> Tuple[str, bool, float]:
    start_time = time.time()
    
    try:
        if ':' in proxy:
            if len(proxy.split(':')) == 2:
                proxy_dict = {
                    "http": f"http://{proxy}",
                    "https": f"http://{proxy}"
                }
            elif len(proxy.split(':')) == 4:
                parts = proxy.split(':')
                proxy_dict = {
                    "http": f"http://{parts[2]}:{parts[3]}@{parts[0]}:{parts[1]}",
                    "https": f"http://{parts[2]}:{parts[3]}@{parts[0]}:{parts[1]}"
                }
            else:
                return proxy, False, 0
        else:
            return proxy, False, 0
        
        response = requests.get(
            "https://yande.re",
            proxies=proxy_dict,
            timeout=3
        )
        
        if response.status_code == 200:
            response_time = time.time() - start_time
            return proxy, True, response_time
        else:
            return proxy, False, 0
            
    except Exception as e:
        return proxy, False, 0

def check_proxies_parallel(proxies: List[str], max_workers: int = 50, max_working: int = 20) -> List[Dict]:
    working_proxies = []
    working_proxies_lock = threading.Lock()
    stop_search = threading.Event()
    
    log(f"[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É {len(proxies)} –ø—Ä–æ–∫—Å–∏ —Å {max_workers} –ø–æ—Ç–æ–∫–∞–º–∏...")
    
    def check_proxy_wrapper(proxy):
        if stop_search.is_set():
            return proxy, False, 0
            
        proxy, is_working, response_time = check_single_proxy(proxy)
        
        if is_working:
            with working_proxies_lock:
                working_proxies.append({
                    "proxy": proxy,
                    "response_time": response_time
                })
                log(f"[BooruSearch] ‚úÖ –†–∞–±–æ—á–∏–π –ø—Ä–æ–∫—Å–∏: {proxy} (–≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {response_time:.2f}—Å)")
                
                if len(working_proxies) >= max_working:
                    stop_search.set()
                    log(f"[BooruSearch] üéØ –ù–∞–π–¥–µ–Ω–æ {max_working} —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ–∫—Å–∏! –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–∏—Å–∫...")
        
        return proxy, is_working, response_time
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_proxy = {executor.submit(check_proxy_wrapper, proxy): proxy for proxy in proxies}
        
        completed = 0
        for future in concurrent.futures.as_completed(future_to_proxy):
            completed += 1
            
            if stop_search.is_set():
                for f in future_to_proxy:
                    f.cancel()
                break
            
            if completed % 100 == 0:
                with working_proxies_lock:
                    log(f"[BooruSearch] –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ: {completed}/{len(proxies)} –ø—Ä–æ–∫—Å–∏ (–Ω–∞–π–¥–µ–Ω–æ —Ä–∞–±–æ—á–∏—Ö: {len(working_proxies)})")
    
    return working_proxies

def save_working_proxies_to_file(working_proxies: List[Dict], filename: str = "rule34_proxies.json"):
    try:
        data_dir = ApplicationLoader.getFilesDirFixed()
        file_path = os.path.join(str(data_dir), filename)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(working_proxies, f, ensure_ascii=False, indent=2)
        
        log(f"[BooruSearch] –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(working_proxies)} —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ–∫—Å–∏ –≤ {file_path}")
    except Exception as e:
        log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")

def load_working_proxies_from_file(filename: str = "rule34_proxies.json") -> List[Dict]:
    try:
        data_dir = ApplicationLoader.getFilesDirFixed()
        file_path = os.path.join(str(data_dir), filename)
        
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                working_proxies = json.load(f)
            log(f"[BooruSearch] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(working_proxies)} –ø—Ä–æ–∫—Å–∏ –∏–∑ —Ñ–∞–π–ª–∞")
            return working_proxies
        else:
            log(f"[BooruSearch] –§–∞–π–ª —Å –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            return []
    except Exception as e:
        log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ —Å –ø—Ä–æ–∫—Å–∏: {e}")
        return []

def get_request_headers(rotate_ua: bool = True) -> dict:
    """–ü–æ–ª—É—á–∏—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ä–æ—Ç–∞—Ü–∏–µ–π User-Agent"""
    headers = {
        "Accept": "application/json, text/plain, */*",
        "Accept-Language": "en-US,en;q=0.9",
        "Accept-Encoding": "gzip, deflate, br",
        "DNT": "1",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
    }
    
    if rotate_ua:
        headers["User-Agent"] = get_random_user_agent()
    else:
        headers["User-Agent"] = USER_AGENTS[0]
    
    return headers

def get_working_proxy(test_url: str = "https://api.rule34.xxx/", rotate_ua: bool = True) -> dict:
    try:
        working_proxies = load_working_proxies_from_file()
        
        if working_proxies:
            random.shuffle(working_proxies)
            
            for proxy_info in working_proxies[:5]:
                proxy = proxy_info['proxy']
                proxy_dict = {"http": f"http://{proxy}", "https": f"http://{proxy}"}
                headers = get_request_headers(rotate_ua)
                
                try:
                    test_response = requests.get(test_url, proxies=proxy_dict, headers=headers, timeout=5)
                    if test_response.status_code == 200:
                        log(f"[BooruSearch] –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–±–æ—á–∏–π –ø—Ä–æ–∫—Å–∏: {proxy}")
                        return proxy_dict
                except Exception:
                    continue
        
        log("[BooruSearch] –†–∞–±–æ—á–∏–µ –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return None
        
    except Exception as e:
        log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–æ–∫—Å–∏: {e}")
        return None


class BooruSearch(BasePlugin):
    def __init__(self):
        super().__init__()
        self._cache = {}
        self._cache_expiry = {}

    def on_plugin_load(self):
        self.add_on_send_message_hook()
        log("rule34_search plugin loaded")
        try:
            if self.get_setting("use_proxy", True):
                data_dir = ApplicationLoader.getFilesDirFixed()
                file_path = os.path.join(str(data_dir), "rule34_proxies.json")
                if not os.path.exists(file_path):
                    log("[BooruSearch] –ù–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –ø—Ä–æ–∫—Å–∏, –∑–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤–∏—á–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ")
                    self.update_proxy_list()
        except Exception as e:
            log(f"[BooruSearch] init proxies check error: {e}")

    def on_plugin_unload(self):
        log("rule34_search plugin unloaded")

    def create_settings(self):
        return [
            Header(text="BooruSearch"),
            Text(text="Rule34", icon="msg_search", create_sub_fragment=self.create_rule34_settings),
            Text(text="Yande.re", icon="msg_search", create_sub_fragment=self.create_yandere_settings),
            Text(text="Danbooru", icon="msg_search", create_sub_fragment=self.create_danbooru_settings),
            Text(text="Safebooru", icon="msg_search", create_sub_fragment=self.create_safebooru_settings),
            Text(text="Gelbooru", icon="msg_search", create_sub_fragment=self.create_gelbooru_settings),
            Text(text="Konachan", icon="msg_search", create_sub_fragment=self.create_konachan_settings),
            Divider(),
            Header(text="–û–±—â–∏–µ"),
            Text(text="–í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", icon="msg_reorder", create_sub_fragment=self.create_output_settings),
            Text(text="–ü—Ä–æ–∫—Å–∏", icon="msg_stories_link", create_sub_fragment=self.create_proxy_settings),
        ]

    def create_rule34_settings(self):
        return [
            Header(text="Rule34 - –¢–µ–≥–∏"),
            Input(
                key="tags_in",
                text=localise("tags_in_text"),
                default="",
                subtext=localise("tags_in_subtext"),
                icon="msg_folders_read"
            ),
            Input(
                key="tags_ex",
                text=localise("tags_ex_text"),
                default="ai_generated",
                subtext=localise("tags_ex_subtext"),
                icon="msg_panel_clear"
            ),
            Divider(),
            Header(text="–§–∏–ª—å—Ç—Ä—ã"),
            Switch(key="antiai", text=localise("antiai_text"), default=True, subtext=localise("antiai_subtext"), icon="msg_photo_settings"),
            Divider(),
            Header(text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"),
            Input(
                key="posts_count",
                text=localise("posts_count_text"),
                default="100",
                subtext=localise("posts_count_subtext"),
                icon="msg_views"
            ),
            Input(
                key="send_count",
                text=localise("send_count_text"),
                default="1",
                subtext=localise("send_count_subtext"),
                icon="filled_button_share"
            ),
        ]

    def create_yandere_settings(self):
        return [
            Header(text="Yande.re - –¢–µ–≥–∏"),
            Input(
                key="yandere_tags_in",
                text=localise("yandere_tags_in_text"),
                default="",
                subtext=localise("yandere_tags_in_subtext"),
                icon="msg_folders_read"
            ),
            Input(
                key="yandere_tags_ex",
                text=localise("yandere_tags_ex_text"),
                default="",
                subtext=localise("yandere_tags_ex_subtext"),
                icon="msg_panel_clear"
            ),
            Divider(),
            Header(text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"),
            Input(
                key="yandere_posts_count",
                text=localise("yandere_posts_count_text"),
                default="100",
                subtext=localise("yandere_posts_count_subtext"),
                icon="msg_views"
            ),
            Input(
                key="yandere_send_count",
                text=localise("yandere_send_count_text"),
                default="1",
                subtext=localise("yandere_send_count_subtext"),
                icon="filled_button_share"
            ),
            Divider(),
            Header(text="–†–µ–π—Ç–∏–Ω–≥"),
            Input(
                key="yandere_rating",
                text=localise("yandere_rating_text"),
                default="",
                subtext=localise("yandere_rating_subtext"),
                icon="msg_photo_settings"
            ),
        ]

    def create_danbooru_settings(self):
        return [
            Header(text="Danbooru - –¢–µ–≥–∏"),
            Input(
                key="danbooru_tags_in",
                text=localise("danbooru_tags_in_text"),
                default="",
                subtext=localise("danbooru_tags_in_subtext"),
                icon="msg_folders_read"
            ),
            Input(
                key="danbooru_tags_ex",
                text=localise("danbooru_tags_ex_text"),
                default="",
                subtext=localise("danbooru_tags_ex_subtext"),
                icon="msg_panel_clear"
            ),
            Divider(),
            Header(text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"),
            Input(
                key="danbooru_posts_count",
                text=localise("danbooru_posts_count_text"),
                default="100",
                subtext=localise("danbooru_posts_count_subtext"),
                icon="msg_views"
            ),
            Input(
                key="danbooru_send_count",
                text=localise("danbooru_send_count_text"),
                default="1",
                subtext=localise("danbooru_send_count_subtext"),
                icon="filled_button_share"
            ),
            Divider(),
            Header(text="–†–µ–π—Ç–∏–Ω–≥"),
            Input(
                key="danbooru_rating",
                text=localise("danbooru_rating_text"),
                default="",
                subtext=localise("danbooru_rating_subtext"),
                icon="msg_photo_settings"
            ),
        ]

    def create_safebooru_settings(self):
        return [
            Header(text="Safebooru - –¢–µ–≥–∏"),
            Input(
                key="safebooru_tags_in",
                text=localise("safebooru_tags_in_text"),
                default="",
                subtext=localise("safebooru_tags_in_subtext"),
                icon="msg_folders_read"
            ),
            Input(
                key="safebooru_tags_ex",
                text=localise("safebooru_tags_ex_text"),
                default="",
                subtext=localise("safebooru_tags_ex_subtext"),
                icon="msg_panel_clear"
            ),
            Divider(),
            Header(text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"),
            Input(
                key="safebooru_posts_count",
                text=localise("safebooru_posts_count_text"),
                default="100",
                subtext=localise("safebooru_posts_count_subtext"),
                icon="msg_views"
            ),
            Input(
                key="safebooru_send_count",
                text=localise("safebooru_send_count_text"),
                default="1",
                subtext=localise("safebooru_send_count_subtext"),
                icon="filled_button_share"
            ),
        ]

    def create_gelbooru_settings(self):
        return [
            Header(text="Gelbooru - –¢–µ–≥–∏"),
            Input(
                key="gelbooru_tags_in",
                text=localise("gelbooru_tags_in_text"),
                default="",
                subtext=localise("gelbooru_tags_in_subtext"),
                icon="msg_folders_read"
            ),
            Input(
                key="gelbooru_tags_ex",
                text=localise("gelbooru_tags_ex_text"),
                default="",
                subtext=localise("gelbooru_tags_ex_subtext"),
                icon="msg_panel_clear"
            ),
            Divider(),
            Header(text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"),
            Input(
                key="gelbooru_posts_count",
                text=localise("gelbooru_posts_count_text"),
                default="100",
                subtext=localise("gelbooru_posts_count_subtext"),
                icon="msg_views"
            ),
            Input(
                key="gelbooru_send_count",
                text=localise("gelbooru_send_count_text"),
                default="1",
                subtext=localise("gelbooru_send_count_subtext"),
                icon="filled_button_share"
            ),
        ]

    def create_konachan_settings(self):
        return [
            Header(text="Konachan - –¢–µ–≥–∏"),
            Input(
                key="konachan_tags_in",
                text=localise("konachan_tags_in_text"),
                default="",
                subtext=localise("konachan_tags_in_subtext"),
                icon="msg_folders_read"
            ),
            Input(
                key="konachan_tags_ex",
                text=localise("konachan_tags_ex_text"),
                default="",
                subtext=localise("konachan_tags_ex_subtext"),
                icon="msg_panel_clear"
            ),
            Divider(),
            Header(text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"),
            Input(
                key="konachan_posts_count",
                text=localise("konachan_posts_count_text"),
                default="100",
                subtext=localise("konachan_posts_count_subtext"),
                icon="msg_views"
            ),
            Input(
                key="konachan_send_count",
                text=localise("konachan_send_count_text"),
                default="1",
                subtext=localise("konachan_send_count_subtext"),
                icon="filled_button_share"
            ),
        ]

    def create_output_settings(self):
        return [
            Header(text="–¢–µ–º–∞ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è"),
            Selector(
                key="theme_style",
                text=localise("theme_text"),
                icon="msg2_permissions",
                default=0,
                items=[localise("theme_item_normal"), localise("theme_item_nso")]
            ),
            Divider(),
            Header(text="–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ"),
            Switch(
                key="show_requested_tags",
                text=localise("show_requested_tags_text"),
                default=True,
                subtext=localise("show_requested_tags_subtext"),
                icon="msg_reorder"
            ),
            Switch(
                key="show_post_tags",
                text=localise("show_post_tags_text"),
                default=True,
                subtext=localise("show_post_tags_subtext"),
                icon="files_storage"
            ),
            Switch(
                key="show_image_link",
                text=localise("show_image_link_text"),
                default=True,
                subtext=localise("show_image_link_subtext"),
                icon="msg_stories_link"
            ),
            Divider(),
            Header(text="–ü–æ–≤–µ–¥–µ–Ω–∏–µ"),
            Switch(
                key="stop_on_not_found",
                text=localise("stop_on_not_found"),
                default=True,
                subtext=localise("stop_on_not_found_subtext"),
                icon="msg_info"
            ),
        ]

    def create_proxy_settings(self):
        return [
            Header(text="–û—Å–Ω–æ–≤–Ω–æ–µ"),
            Switch(
                key="use_proxy",
                text=localise("use_proxy_text"),
                default=True,
                subtext=localise("use_proxy_subtext"),
                icon="msg_stories_link"
            ),
            Text(
                text=localise("update_proxies_text"), 
                accent=True, 
                on_click=lambda v: self.update_proxy_list(),
                icon="msg_info"
            ),
            Divider(),
            Header(text="–†–æ—Ç–∞—Ü–∏—è"),
            Switch(
                key="proxy_rotate",
                text=localise("proxy_rotate_text"),
                default=True,
                subtext=localise("proxy_rotate_subtext"),
                icon="msg_reorder"
            ),
            Switch(
                key="proxy_rotate_ua",
                text=localise("proxy_user_agent_text"),
                default=True,
                subtext=localise("proxy_user_agent_subtext"),
                icon="msg_panel_clear"
            ),
        ]

    def get_image_safebooru(self, query):
        try:
            tags_in_setting = self.get_setting("safebooru_tags_in", "")
            tags_ex_setting = self.get_setting("safebooru_tags_ex", "")
            posts_count = min(int(self.get_setting("safebooru_posts_count", "100")), 1000)
            use_proxy = self.get_setting("use_proxy", True)
            
            query_parts = query.split()
            include_tags = [p for p in query_parts if not p.startswith('-')]
            exclude_tags = [p[1:] for p in query_parts if p.startswith('-')]
            
            all_include = []
            if tags_in_setting:
                all_include.extend(tags_in_setting.split())
            all_include.extend(include_tags)
            search_tags = ' '.join(all_include)
            
            all_exclude_tags = tags_ex_setting.split("; ") + exclude_tags
            tags_ex = [tag.strip() for tag in all_exclude_tags if tag.strip()]
            if tags_ex:
                for tag in tags_ex:
                    search_tags += f' -{tag}'
            
            log(f"[BooruSearch] Safebooru –ø–æ–∏—Å–∫: '{search_tags}'")
            
            try:
                response = requests.get(
                    f"https://safebooru.org/index.php?page=dapi&s=post&q=index&limit={posts_count}&tags={search_tags}&json=1",
                    timeout=10
                )
                response.raise_for_status()
            except Exception as e:
                if use_proxy:
                    proxy = get_working_proxy()
                    if proxy:
                        response = requests.get(
                            f"https://safebooru.org/index.php?page=dapi&s=post&q=index&limit={posts_count}&tags={search_tags}&json=1",
                            proxies=proxy,
                            timeout=10
                        )
                        response.raise_for_status()
                    else:
                        raise
                else:
                    raise
            
            data = response.json()
            if not isinstance(data, list) or not data:
                return localise("not_found")
            
            post = random.choice(data)
            tags = post.get('tags', '').split() if isinstance(post.get('tags'), str) else []
            image_url = post.get('file_url') or post.get('sample_url')
            if not image_url:
                return localise("not_found")
            
            return {
                'id': post.get('id'),
                'file_url': image_url,
                'tags': tags,
                'rating': ''
            }
        except Exception as e:
            log(f"[BooruSearch] –û—à–∏–±–∫–∞ Safebooru: {e}")
            return None

    def get_image_gelbooru(self, query):
        try:
            tags_in_setting = self.get_setting("gelbooru_tags_in", "")
            tags_ex_setting = self.get_setting("gelbooru_tags_ex", "")
            posts_count = min(int(self.get_setting("gelbooru_posts_count", "100")), 100)
            use_proxy = self.get_setting("use_proxy", True)
            
            query_parts = query.split()
            include_tags = [p for p in query_parts if not p.startswith('-')]
            exclude_tags = [p[1:] for p in query_parts if p.startswith('-')]
            
            all_include = []
            if tags_in_setting:
                all_include.extend(tags_in_setting.split())
            all_include.extend(include_tags)
            search_tags = ' '.join(all_include)
            
            all_exclude_tags = tags_ex_setting.split("; ") + exclude_tags
            tags_ex = [tag.strip() for tag in all_exclude_tags if tag.strip()]
            if tags_ex:
                for tag in tags_ex:
                    search_tags += f' -{tag}'
            
            log(f"[BooruSearch] Gelbooru –ø–æ–∏—Å–∫: '{search_tags}'")
            
            # Updated API endpoint with API key and user ID
            base_url = "https://gelbooru.com/index.php?page=dapi&s=post&q=index"
            params = {
                'tags': search_tags,
                'limit': posts_count,
                'json': 1,
                'api_key': 'd57401332958011ad38a76d4fdeb7e3035f687ad46bb915d29e38581f17240c91373c2d67b5fdfbffe47736b84cdf285e2aed24affc4601f217a7bb185d06311',
                'user_id': '1861787'
            }
            
            try:
                response = requests.get(base_url, params=params, timeout=10)
                response.raise_for_status()
            except Exception as e:
                if use_proxy:
                    proxy = get_working_proxy()
                    if proxy:
                        response = requests.get(base_url, params=params, proxies=proxy, timeout=10)
                        response.raise_for_status()
                    else:
                        raise
                else:
                    raise
            
            data = response.json()
            if not data or 'post' not in data or not data['post']:
                return localise("not_found")
            
            posts = data['post']
            if not isinstance(posts, list):
                posts = [posts]  # Handle case when only one post is returned
                
            if not posts:
                return localise("not_found")
                
            post = random.choice(posts)
            tags = post.get('tags', '').split() if isinstance(post.get('tags'), str) else []
            image_url = post.get('file_url') or post.get('sample_url')
            
            if not image_url:
                return localise("not_found")
            
            return {
                'id': post.get('id'),
                'file_url': image_url,
                'tags': tags,
                'rating': post.get('rating', '')
            }
        except Exception as e:
            log(f"[BooruSearch] –û—à–∏–±–∫–∞ Gelbooru: {e}")
            return None


    def get_image_konachan(self, query):
        try:
            tags_in_setting = self.get_setting("konachan_tags_in", "")
            tags_ex_setting = self.get_setting("konachan_tags_ex", "")
            posts_count = min(int(self.get_setting("konachan_posts_count", "100")), 100)
            use_proxy = self.get_setting("use_proxy", True)
            
            query_parts = query.split()
            include_tags = [p for p in query_parts if not p.startswith('-')]
            exclude_tags = [p[1:] for p in query_parts if p.startswith('-')]
            
            all_include = []
            if tags_in_setting:
                all_include.extend(tags_in_setting.split())
            all_include.extend(include_tags)
            search_tags = ' '.join(all_include)
            
            all_exclude_tags = tags_ex_setting.split("; ") + exclude_tags
            tags_ex = [tag.strip() for tag in all_exclude_tags if tag.strip()]
            if tags_ex:
                for tag in tags_ex:
                    search_tags += f' -{tag}'
            
            log(f"[BooruSearch] Konachan –ø–æ–∏—Å–∫: '{search_tags}'")
            
            try:
                response = requests.get(
                    f"https://konachan.com/post.json?limit={posts_count}&tags={search_tags}",
                    timeout=10
                )
                response.raise_for_status()
            except Exception as e:
                if use_proxy:
                    proxy = get_working_proxy()
                    if proxy:
                        response = requests.get(
                            f"https://konachan.com/post.json?limit={posts_count}&tags={search_tags}",
                            proxies=proxy,
                            timeout=10
                        )
                        response.raise_for_status()
                    else:
                        raise
                else:
                    raise
            
            data = response.json()
            if not isinstance(data, list) or not data:
                return localise("not_found")
            
            post = random.choice(data)
            tags = post.get('tags', '').split() if isinstance(post.get('tags'), str) else []
            image_url = post.get('jpeg_url') or post.get('sample_url') or post.get('file_url')
            if not image_url:
                return localise("not_found")
            
            return {
                'id': post.get('id'),
                'file_url': image_url,
                'tags': tags,
                'rating': ''
            }
        except Exception as e:
            log(f"[BooruSearch] –û—à–∏–±–∫–∞ Konachan: {e}")
            return None

    def get_image(self, query):
        tags_in_setting = self.get_setting("tags_in", "")
        tags_ex_setting = self.get_setting("tags_ex", "ai_generated")
        antiai = self.get_setting("antiai", True)
        posts_count = int(self.get_setting("posts_count", "100"))
        use_proxy = self.get_setting("use_proxy", True)
        
       
        query_parts = query.split()
        include_tags = []
        exclude_tags = []
        
        for part in query_parts:
            if part.startswith('-'):
                exclude_tags.append(part[1:]) 
            else:
                include_tags.append(part)
        
        search_tags = f"{tags_in_setting} {' '.join(include_tags)}".strip()
        

        all_exclude_tags = tags_ex_setting.split("; ") + exclude_tags
        tags_ex = [tag.strip() for tag in all_exclude_tags if tag.strip()]
        
        log(f"[BooruSearch] –í–∫–ª—é—á–∞—é—â–∏–µ —Ç–µ–≥–∏: {include_tags}")
        log(f"[BooruSearch] –ò—Å–∫–ª—é—á–∞—é—â–∏–µ —Ç–µ–≥–∏ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞: {exclude_tags}")
        log(f"[BooruSearch] –û–±—â–∏–µ –∏—Å–∫–ª—é—á–∞—é—â–∏–µ —Ç–µ–≥–∏: {tags_ex}")

        
        if antiai:
            anti_ai_tags = ['-ai_generated', '-stable_diffusion', '-midjourney', '-artificial_intelligence', '-neural_network', '-machine_learning', '-deepfake', '-ai_art', '-ai-generated', '-generated_by_ai', '-dall_e', '-dalle', '-novelai', '-waifu_diffusion']
            search_tags += ' ' + ' '.join(anti_ai_tags)
            log(f"[BooruSearch] –î–æ–±–∞–≤–ª–µ–Ω—ã –∞–Ω—Ç–∏-–ò–ò —Ç–µ–≥–∏ –≤ –∑–∞–ø—Ä–æ—Å")
        
        
        if tags_ex:
            exclude_tags_api = ['-' + tag for tag in tags_ex]
            search_tags += ' ' + ' '.join(exclude_tags_api)
            log(f"[BooruSearch] –î–æ–±–∞–≤–ª–µ–Ω—ã –∏—Å–∫–ª—é—á–∞—é—â–∏–µ —Ç–µ–≥–∏ –≤ –∑–∞–ø—Ä–æ—Å: {exclude_tags_api}")
        
        log(f"[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫. –ó–∞–ø—Ä–æ—Å: '{search_tags}', –ª–∏–º–∏—Ç: {posts_count}")
        log(f"[BooruSearch] –ò—Å–∫–ª—é—á–∞—é—â–∏–µ —Ç–µ–≥–∏: {tags_ex}")
        log(f"[BooruSearch] –ê–Ω—Ç–∏-AI –≤–∫–ª—é—á–µ–Ω: {antiai}")

        try:
            # Build API URL with JSON format
            base_url = "https://api.rule34.xxx/index.php"
            params = {
                'page': 'dapi',
                's': 'post',
                'q': 'index',
                'limit': posts_count,
                'tags': search_tags,
                'json': 1,  # Request JSON format
                'api_key': 'd82f6db279ce94313e629e791533d456a4309dfeb528ddab6eee4b7472156f0def07ebfd3e64b9dddbf0d3b78f227ba8a5f386533ef1ccb1377d8a97481811dc',
                'user_id': '5255009'
            }

            log("[BooruSearch] –ü—Ä–æ–±—É–µ–º –∑–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏...")
            try:
                response = requests.get(base_url, params=params, timeout=2)
                response.raise_for_status()
                log("[BooruSearch] –ó–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏ —É—Å–ø–µ—à–µ–Ω")
            except Exception as e:
                log(f"[BooruSearch] –ó–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏ –Ω–µ —É–¥–∞–ª—Å—è: {e}")
               
                if use_proxy:
                    log("[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–±–æ—Ä –ø—Ä–æ–∫—Å–∏...")
                    proxy_dict = get_working_proxy()
                    if proxy_dict:
                        log(f"[BooruSearch] –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏!")
                        response = requests.get(base_url, params=params, proxies=proxy_dict, timeout=10)
                        response.raise_for_status()
                    else:
                        log("[BooruSearch] –†–∞–±–æ—á–∏–µ –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏")
                        response = requests.get(base_url, params=params, timeout=10)
                        response.raise_for_status()
                else:
                    log("[BooruSearch] –ü—Ä–æ–∫—Å–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏ –µ—â–µ —Ä–∞–∑")
                    response = requests.get(base_url, params=params, timeout=10)
                    response.raise_for_status()
            
            # Parse JSON response
            data = response.json()
            if not data:
                log("[BooruSearch] –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç API")
                BulletinHelper.show_error(localise("not_found"))
                return localise("not_found")
            
            posts_list = data if isinstance(data, list) else []

            log(f"[BooruSearch] –ü–æ–ª—É—á–µ–Ω–æ –ø–æ—Å—Ç–æ–≤ —Å API: {len(posts_list)}")

            if not posts_list:
                log("[BooruSearch] –ü–æ—Å—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
                BulletinHelper.show_error(localise("not_found"))
                return localise("not_found")

           
            filtered_posts = posts_list
            log(f"[BooruSearch] API —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–ª –∏—Å–∫–ª—é—á–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ {len(filtered_posts)} –ø–æ—Å—Ç–æ–≤")
            
            if not filtered_posts:
                log("[BooruSearch] –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –ø–æ—Å—Ç–æ–≤ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏!")
                BulletinHelper.show_error(localise("not_found_filtered"))
                return localise("not_found_filtered")

            random_post = random.choice(filtered_posts)
            log(f"[BooruSearch] –í—ã–±—Ä–∞–Ω —Å–ª—É—á–∞–π–Ω—ã–π –ø–æ—Å—Ç ID: {random_post.get('id', 'unknown')}")
            
            # Extract tags - they come as a space-separated string from API
            tags = random_post.get('tags', '')
            if isinstance(tags, str):
                tags = tags.split() if tags else []
            
            # Get image URL
            image_url = random_post.get('sample_url') or random_post.get('file_url')
            if not image_url:
                log("[BooruSearch] –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                BulletinHelper.show_error(localise("not_found"))
                return localise("not_found")

            return {
                'id': random_post.get('id'),
                'file_url': image_url,
                'tags': tags,
                'rating': random_post.get('rating', '')
            }

        except requests.exceptions.RequestException as e:
            log(f"[BooruSearch] –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            if "SSLCertVerificationError" in str(e):
                BulletinHelper.show_error("–°–∞–π—Ç BooruSearch.xxx –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω! –í–∫–ª—é—á–∏—Ç–µ VPN.")
            else:
                BulletinHelper.show_error(localise("request_error").format(e=e))
            return None

    def get_image_yandere(self, query):
        try:
            tags_in_setting = self.get_setting("yandere_tags_in", "")
            tags_ex_setting = self.get_setting("yandere_tags_ex", "")
            posts_count = min(int(self.get_setting("yandere_posts_count", "100")), 200)  # Yande.re max: 200
            use_proxy = self.get_setting("use_proxy", True)
            rating_filter_raw = self.get_setting("yandere_rating", "")
            rating_filter = str(rating_filter_raw).strip().lower() if rating_filter_raw else ""
            log(f"[BooruSearch] Yandere rating filter raw: '{rating_filter_raw}', processed: '{rating_filter}'")

            query_parts = query.split()
            include_tags = []
            exclude_tags = []
            for part in query_parts:
                if part.startswith('-'):
                    exclude_tags.append(part[1:])
                else:
                    include_tags.append(part)

            # Build search tags with proper spacing for multi-tag search
            all_include = []
            if tags_in_setting:
                all_include.extend(tags_in_setting.split())
            all_include.extend(include_tags)
            
            search_tags = ' '.join(all_include)
            
            # Add exclude tags
            all_exclude_tags = tags_ex_setting.split("; ") + exclude_tags
            tags_ex = [tag.strip() for tag in all_exclude_tags if tag.strip()]
            if tags_ex:
                for tag in tags_ex:
                    search_tags += f' -{tag}'

            if rating_filter:
                rating_map = {'safe': 's', 'questionable': 'q', 'explicit': 'e'}
                rating_code = rating_map.get(rating_filter, rating_filter)
                search_tags += f' rating:{rating_code}'

            log(f"[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫. –ó–∞–ø—Ä–æ—Å: '{search_tags}', –ª–∏–º–∏—Ç: {posts_count}")
            log(f"[BooruSearch] –ò—Å–∫–ª—é—á–∞—é—â–∏–µ —Ç–µ–≥–∏: {tags_ex}")
            try:
                log("[BooruSearch] –ü—Ä–æ–±—É–µ–º –∑–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏...")
                response = requests.get(
                    f"https://yande.re/post.json?limit={posts_count}&tags={search_tags}",
                    timeout=2
                )
                response.raise_for_status()
                log("[BooruSearch] –ó–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏ —É—Å–ø–µ—à–µ–Ω")
            except Exception as e:
                log(f"[BooruSearch] –ó–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏ –Ω–µ —É–¥–∞–ª—Å—è: {e}")
                if use_proxy:
                    log("[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–±–æ—Ä –ø—Ä–æ–∫—Å–∏...")
                    proxy_dict = get_working_proxy("https://yande.re/post.json?limit=1")
                    if proxy_dict:
                        log("[BooruSearch] –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏!")
                        response = requests.get(
                            f"https://yande.re/post.json?limit={posts_count}&tags={search_tags}",
                            timeout=2,
                            proxies=proxy_dict
                        )
                        response.raise_for_status()
                    else:
                        log("[BooruSearch] –†–∞–±–æ—á–∏–µ –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏")
                        response = requests.get(
                            f"https://yande.re/post.json?limit={posts_count}&tags={search_tags}",
                            timeout= 10
                        )
                        response.raise_for_status()
                else:
                    log("[BooruSearch] –ü—Ä–æ–∫—Å–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏ –µ—â–µ —Ä–∞–∑")
                    response = requests.get(
                        f"https://yande.re/post.json?limit={posts_count}&tags={search_tags}",
                        timeout=10
                    )
                    response.raise_for_status()

            data = response.json()
            log(f"[BooruSearch] –ü–æ–ª—É—á–µ–Ω–æ –ø–æ—Å—Ç–æ–≤ —Å API: {len(data)}")
            if not isinstance(data, list) or not data:
                log("[BooruSearch] –ü–æ—Å—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
                return localise("not_found")

            post = random.choice(data)
            log(f"[BooruSearch] –í—ã–±—Ä–∞–Ω —Å–ª—É—á–∞–π–Ω—ã–π –ø–æ—Å—Ç ID: {post.get('id', 'unknown')}")
            # Normalize fields similar to BooruSearch
            tags = []
            try:
                if isinstance(post.get('tags'), str):
                    tags = post.get('tags', '').split()
            except Exception:
                tags = []
            image_url = post.get('jpeg_url') or post.get('sample_url') or post.get('file_url')
            if not image_url:
                return localise("not_found")
            rating = post.get('rating', 'unknown')
            rating_display = localise_rating(rating, 'yandere')

            return {
                'id': post.get('id'),
                'file_url': image_url,
                'tags': tags,
                'rating': rating_display
            }
        except requests.exceptions.RequestException as e:
            log(f"[BooruSearch] –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ Yande.re: {e}")
            if "SSLCertVerificationError" in str(e):
                BulletinHelper.show_error("–°–∞–π—Ç Yande.re –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω! –í–∫–ª—é—á–∏—Ç–µ VPN.")
            else:
                BulletinHelper.show_error(localise("request_error").format(e=e))
            return None
        except json.JSONDecodeError as e:
            log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç Yande.re: {e}")
            BulletinHelper.show_error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Yande.re")
            return None
        except Exception as e:
            log(f"[BooruSearch] –û–±—â–∞—è –æ—à–∏–±–∫–∞ Yande.re: {e}")
            BulletinHelper.show_error(localise("general_data_error").format(e=e))
            return None

    def get_image_danbooru(self, query):
        try:
            tags_in_setting = self.get_setting("danbooru_tags_in", "")
            tags_ex_setting = self.get_setting("danbooru_tags_ex", "")
            posts_count = min(int(self.get_setting("danbooru_posts_count", "100")), 200)  # Danbooru max: 200
            use_proxy = self.get_setting("use_proxy", True)
            rating_filter_raw = self.get_setting("danbooru_rating", "")
            rating_filter = str(rating_filter_raw).strip().lower() if rating_filter_raw else ""
            log(f"[BooruSearch] Danbooru rating filter raw: '{rating_filter_raw}', processed: '{rating_filter}'")

            query_parts = query.split()
            include_tags = []
            exclude_tags = []
            for part in query_parts:
                if part.startswith('-'):
                    exclude_tags.append(part[1:])
                else:
                    include_tags.append(part)

            all_include = []
            if tags_in_setting:
                all_include.extend(tags_in_setting.split())
            all_include.extend(include_tags)
            
            search_tags = ' '.join(all_include)
            all_exclude_tags = tags_ex_setting.split("; ") + exclude_tags
            tags_ex = [tag.strip() for tag in all_exclude_tags if tag.strip()]
            if tags_ex:
                for tag in tags_ex:
                    search_tags += f' -{tag}'
            
            if rating_filter:
                rating_map = {'general': 'g', 'sensitive': 's', 'questionable': 'q', 'explicit': 'e'}
                rating_code = rating_map.get(rating_filter, rating_filter)
                search_tags += f' rating:{rating_code}'

            log(f"[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫. –ó–∞–ø—Ä–æ—Å: '{search_tags}', –ª–∏–º–∏—Ç: {posts_count}")
            log(f"[BooruSearch] –ò—Å–∫–ª—é—á–∞—é—â–∏–µ —Ç–µ–≥–∏: {tags_ex}")
            base = "https://danbooru.donmai.us/posts.json"
            params = {
                'limit': posts_count,
                'tags': search_tags,
            }

            try:
                log("[BooruSearch] –ü—Ä–æ–±—É–µ–º –∑–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏...")
                response = requests.get(base, params=params, timeout=5)
                response.raise_for_status()
                log("[BooruSearch] –ó–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏ —É—Å–ø–µ—à–µ–Ω")
            except Exception as e:
                log(f"[BooruSearch] –ó–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏ –Ω–µ —É–¥–∞–ª—Å—è: {e}")
                if use_proxy:
                    log("[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–±–æ—Ä –ø—Ä–æ–∫—Å–∏...")
                    proxy_dict = get_working_proxy("https://danbooru.donmai.us/posts.json?limit=1")
                    if proxy_dict:
                        log("[BooruSearch] –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏!")
                        response = requests.get(base, params=params, timeout=10, proxies=proxy_dict)
                        response.raise_for_status()
                    else:
                        log("[BooruSearch] –†–∞–±–æ—á–∏–µ –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏")
                        response = requests.get(base, params=params, timeout=10)
                        response.raise_for_status()
                else:
                    log("[BooruSearch] –ü—Ä–æ–∫—Å–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏ –µ—â–µ —Ä–∞–∑")
                    response = requests.get(base, params=params, timeout=10)
                    response.raise_for_status()

            data = response.json()
            log(f"[BooruSearch] –ü–æ–ª—É—á–µ–Ω–æ –ø–æ—Å—Ç–æ–≤ —Å API: {len(data)}")
            if not isinstance(data, list) or not data:
                log("[BooruSearch] –ü–æ—Å—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
                return localise("not_found")

            post = random.choice(data)
            log(f"[BooruSearch] –í—ã–±—Ä–∞–Ω —Å–ª—É—á–∞–π–Ω—ã–π –ø–æ—Å—Ç ID: {post.get('id', 'unknown')}")
            tags_str = post.get('tag_string', '') or ''
            tags = tags_str.split()
            image_url = post.get('file_url') or post.get('large_file_url') or post.get('preview_file_url')
            if not image_url:
                return localise("not_found")
            
            # Get rating
            rating = post.get('rating', 'unknown')
            rating_display = localise_rating(rating, 'danbooru')

            return {
                'id': post.get('id'),
                'file_url': image_url,
                'tags': tags,
                'rating': rating_display
            }
        except Exception as e:
            log(f"[BooruSearch] –û—à–∏–±–∫–∞: {e}")
            BulletinHelper.show_error(localise("general_data_error").format(e=e))
            return None

    def on_send_message_hook(self, account, params):
        if not hasattr(params, 'message') or not isinstance(params.message, str):
            return HookResult()

        msg = params.message.strip()
        usage = localise("usage")
        try:
            if msg.startswith(".proxy_get"):
                self.update_proxy_list()
                params.message = localise("proxy_update_started")
                return HookResult(strategy=HookStrategy.CANCEL)
        except Exception as e:
            log(f"[BooruSearch] proxy_get error: {e}")

        if not (msg.startswith(".r34") or msg.startswith(".yandere") or msg.startswith(".danbooru") or msg.startswith(".safebooru") or msg.startswith(".gelbooru") or msg.startswith(".konachan") or msg.startswith(".random")):
            return HookResult()

        cmd_type = ".r34"
        if msg.startswith(".yandere"):
            cmd_type = ".yandere"
            log("[BooruSearch] –ö–æ–º–∞–Ω–¥–∞ .yandere –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞")
        elif msg.startswith(".danbooru"):
            cmd_type = ".danbooru"
            log("[BooruSearch] –ö–æ–º–∞–Ω–¥–∞ .danbooru –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞")
        elif msg.startswith(".safebooru"):
            cmd_type = ".safebooru"
            log("[BooruSearch] –ö–æ–º–∞–Ω–¥–∞ .safebooru –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞")
        elif msg.startswith(".gelbooru"):
            cmd_type = ".gelbooru"
            log("[BooruSearch] –ö–æ–º–∞–Ω–¥–∞ .gelbooru –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞")
        elif msg.startswith(".konachan"):
            cmd_type = ".konachan"
            log("[BooruSearch] –ö–æ–º–∞–Ω–¥–∞ .konachan –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞")
        elif msg.startswith(".random"):
            cmd_type = ".random"
            log("[BooruSearch] –ö–æ–º–∞–Ω–¥–∞ .random –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞")
        else:
            log("[BooruSearch] –ö–æ–º–∞–Ω–¥–∞ .r34 –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞")      

        parts = msg.split(" ", 1)
        query = ""
        if len(parts) > 1:
            query = parts[1].strip()
        send_n = 1
        try:
            if cmd_type == ".yandere":
                send_n = int(self.get_setting("yandere_send_count", "1"))
            elif cmd_type == ".danbooru":
                send_n = int(self.get_setting("danbooru_send_count", "1"))
            elif cmd_type == ".safebooru":
                send_n = int(self.get_setting("safebooru_send_count", "1"))
            elif cmd_type == ".gelbooru":
                send_n = int(self.get_setting("gelbooru_send_count", "1"))
            elif cmd_type == ".konachan":
                send_n = int(self.get_setting("konachan_send_count", "1"))
            elif cmd_type == ".random":
                send_n = int(self.get_setting("send_count", "1"))
            else:
                send_n = int(self.get_setting("send_count", "1"))
        except Exception:
            send_n = 1
        try:
            tokens = query.split()
            if tokens and tokens[-1].isdigit():
                send_n = int(tokens[-1])
                tokens = tokens[:-1]
                query = " ".join(tokens)
        except Exception:
            pass
        try:
            send_n = max(1, min(10, int(send_n)))
        except Exception:
            send_n = 1

        log(f"[BooruSearch] –ó–∞–ø—Ä–æ—Å: '{query}'")

        
        include_tags = [part for part in query.split() if not part.startswith('-')]
        if cmd_type == ".yandere":
            tags_in_setting = self.get_setting("yandere_tags_in", "").strip()
        elif cmd_type == ".danbooru":
            tags_in_setting = self.get_setting("danbooru_tags_in", "").strip()
        else:
            tags_in_setting = self.get_setting("tags_in", "nude").strip()
        
        if not include_tags and not tags_in_setting:
            if cmd_type == ".yandere":
                BulletinHelper.show_error("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: .yandere [—Ç–µ–≥–∏]\n–ü—Ä–∏–º–µ—Ä: .yandere anime 1girl")
                return HookResult(strategy=HookStrategy.CANCEL)
            elif cmd_type == ".danbooru":
                BulletinHelper.show_error("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: .danbooru [—Ç–µ–≥–∏]\n–ü—Ä–∏–º–µ—Ä: .danbooru touhou solo")
                return HookResult(strategy=HookStrategy.CANCEL)
            else:
                params.message = usage
                return HookResult(strategy=HookStrategy.MODIFY, params=params)

        def search_and_reply(search_query, peer, reply_to_msg=None, reply_to_top_msg=None, send_n: int = 1):
            log(f"[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –≤ –ø–æ—Ç–æ–∫–µ. –ó–∞–ø—Ä–æ—Å: '{search_query}', –æ—Ç–ø—Ä–∞–≤–∏–º {send_n} –ø–æ—Å—Ç(–∞)")
            stop_on_not_found = self.get_setting("stop_on_not_found", True)
            for idx in range(send_n):
                try:
                    if cmd_type == ".yandere":
                        result = self.get_image_yandere(search_query)
                    elif cmd_type == ".danbooru":
                        result = self.get_image_danbooru(search_query)
                    elif cmd_type == ".safebooru":
                        result = self.get_image_safebooru(search_query)
                    elif cmd_type == ".gelbooru":
                        result = self.get_image_gelbooru(search_query)
                    elif cmd_type == ".konachan":
                        result = self.get_image_konachan(search_query)
                    elif cmd_type == ".random":
                        sources = [self.get_image, self.get_image_yandere, self.get_image_danbooru, self.get_image_safebooru, self.get_image_gelbooru, self.get_image_konachan]
                        result = random.choice(sources)(search_query)
                    else:
                        result = self.get_image(search_query)
                    
                    if isinstance(result, str) and stop_on_not_found and result == localise("not_found"):
                        log(f"[BooruSearch] –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏ stop_on_not_found=True, –ø—Ä–µ—Ä—ã–≤–∞–µ–º –ø–æ–∏—Å–∫")
                        BulletinHelper.show_error(result)
                        break

                    log(f"[BooruSearch] –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ –ø–æ–ª—É—á–µ–Ω: {type(result)}")

                    if isinstance(result, dict) and result.get("file_url"):
                        log(f"[BooruSearch] –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º: {result.get('id', 'unknown')}")
                        if cmd_type == ".yandere":
                            tags_in_setting = self.get_setting("yandere_tags_in", "")
                        elif cmd_type == ".danbooru":
                            tags_in_setting = self.get_setting("danbooru_tags_in", "")
                        else:
                            tags_in_setting = self.get_setting("tags_in", "")
                        requested_tags = (tags_in_setting + (" " + query if query else "")).strip()
                        requested_tags_str = requested_tags if requested_tags else "(–ø—É—Å—Ç–æ)"
                        tags_list = result.get('tags', [])
                        if isinstance(tags_list, str):
                            tags_list = tags_list.split() if tags_list else []
                        post_tags = ", ".join(tags_list)
                        image_url = result.get("file_url")
                        rating = result.get('rating', '') if (cmd_type == ".yandere" or cmd_type == ".danbooru") else ''
                        message_text = self._build_caption_text(requested_tags_str, post_tags, image_url, rating)

                        parsed_message = parse_markdown(message_text)
                        try:
                            ext = os.path.splitext(image_url.split('?')[0])[1].lower()
                        except Exception:
                            ext = ""
                        if ext in (".mp4", ".webm", ".gif"):
                            try:
                                send_message({
                                    "peer": peer,
                                    "message": parsed_message.text,
                                    "entities": [entity.to_tlrpc_object() for entity in parsed_message.entities],
                                    **({"replyToMsg": reply_to_msg} if reply_to_msg is not None else {}),
                                    **({"replyToTopMsg": reply_to_top_msg} if reply_to_top_msg is not None else {})
                                })
                            except Exception as se:
                                log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –≤–∏–¥–µ–æ/GIF: {se}")
                            continue
                        try:
                            local_path, is_image = self._download_media(image_url)
                        except Exception as de:
                            log(f"[BooruSearch] –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –º–µ–¥–∏–∞: {de}")
                            message_params = {
                                "peer": peer,
                                "message": parsed_message.text,
                                "entities": [entity.to_tlrpc_object() for entity in parsed_message.entities]
                            }
                            if reply_to_msg is not None:
                                message_params["replyToMsg"] = reply_to_msg
                            if reply_to_top_msg is not None:
                                message_params["replyToTopMsg"] = reply_to_top_msg
                            send_message(message_params)
                            continue

                        try:
                            if is_image:
                                helper = get_send_messages_helper()
                                photo = helper.generatePhotoSizes(local_path, None)
                                if photo is not None:
                                    send_message({
                                        "peer": peer,
                                        "photo": photo,
                                        "path": local_path,
                                        "caption": parsed_message.text,
                                        "entities": [e.to_tlrpc_object() for e in parsed_message.entities],
                                        **({"replyToMsg": reply_to_msg} if reply_to_msg is not None else {}),
                                        **({"replyToTopMsg": reply_to_top_msg} if reply_to_top_msg is not None else {})
                                    })
                                else:
                                    send_message({
                                        "peer": peer,
                                        "message": parsed_message.text,
                                        "entities": [e.to_tlrpc_object() for e in parsed_message.entities],
                                        **({"replyToMsg": reply_to_msg} if reply_to_msg is not None else {}),
                                        **({"replyToTopMsg": reply_to_top_msg} if reply_to_top_msg is not None else {})
                                    })
                            else:
                                send_message({
                                    "peer": peer,
                                    "path": local_path,
                                    **({"replyToMsg": reply_to_msg} if reply_to_msg is not None else {}),
                                    **({"replyToTopMsg": reply_to_top_msg} if reply_to_top_msg is not None else {})
                                })
                                time.sleep(0.2)
                                send_message({
                                    "peer": peer,
                                    "message": parsed_message.text,
                                    "entities": [e.to_tlrpc_object() for e in parsed_message.entities],
                                    **({"replyToMsg": reply_to_msg} if reply_to_msg is not None else {}),
                                    **({"replyToTopMsg": reply_to_top_msg} if reply_to_top_msg is not None else {})
                                })
                        except Exception as se:
                            log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –º–µ–¥–∏–∞: {se}")
                            send_message({
                                "peer": peer,
                                "message": parsed_message.text,
                                "entities": [e.to_tlrpc_object() for e in parsed_message.entities],
                                **({"replyToMsg": reply_to_msg} if reply_to_msg is not None else {}),
                                **({"replyToTopMsg": reply_to_top_msg} if reply_to_top_msg is not None else {})
                            })
                    elif isinstance(result, str):
                        log(f"[BooruSearch] –ü–æ–∫–∞–∑—ã–≤–∞–µ–º Bulletin: {result}")
                        BulletinHelper.show_error(result)
                    elif result is None:
                        log(f"[BooruSearch] –†–µ–∑—É–ª—å—Ç–∞—Ç None, –Ω–∏—á–µ–≥–æ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º")
                        pass
                    else:
                        log(f"[BooruSearch] –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {type(result)}")
                        BulletinHelper.show_error(localise("unexpected_url_error"))

                except Exception as e:
                    log(f"[BooruSearch] –û—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ –ø–æ–∏—Å–∫–∞: {e}")
                    BulletinHelper.show_error(localise("search_thread_error").format(e=e))
                # small delay between sends
                time.sleep(0.3)

        try:
            BulletinHelper.show_info(localise("searching"))
        except Exception as e:
            log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∏–∞–ª–æ–≥–∞: {e}")

        log("[BooruSearch] –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –ø–æ–∏—Å–∫–∞")
        
        threading.Thread(target=lambda: search_and_reply(query, params.peer, params.replyToMsg, params.replyToTopMsg, send_n), daemon=True).start()

        params.message = localise("searching")
        return HookResult(strategy=HookStrategy.CANCEL)

    def update_proxy_list(self):
        def update_proxies_background():
            try:
                BulletinHelper.show_info(localise("proxy_update_started"))
                log("[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–∫—Å–∏...")
                
                proxy_url = "https://cdn.jsdelivr.net/gh/proxifly/free-proxy-list@main/proxies/all/data.txt"
                
                all_proxies = get_proxy_list_from_url(proxy_url)
                log(f"[BooruSearch] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_proxies)} –ø—Ä–æ–∫—Å–∏ –∏–∑ {proxy_url}")
                
                if not all_proxies:
                    BulletinHelper.show_error(localise("proxy_update_error").format(error="–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–∫—Å–∏"))
                    return
                
                unique_proxies = list(set(all_proxies))
                log(f"[BooruSearch] –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏: {len(unique_proxies)}")
                
                max_proxies_to_check = 2000
                if len(unique_proxies) > max_proxies_to_check:
                    unique_proxies = unique_proxies[:max_proxies_to_check]
                    log(f"[BooruSearch] –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –¥–æ {max_proxies_to_check} –ø—Ä–æ–∫—Å–∏")
                
                working_proxies = check_proxies_parallel(unique_proxies, max_workers=100, max_working=30)
                
                if working_proxies:
                    working_proxies.sort(key=lambda x: x['response_time'])
                    
                    save_working_proxies_to_file(working_proxies)
                    
                    BulletinHelper.show_success(localise("proxy_update_success").format(count=len(working_proxies)))
                    log(f"[BooruSearch] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ù–∞–π–¥–µ–Ω–æ {len(working_proxies)} —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ–∫—Å–∏")
                else:
                    BulletinHelper.show_error(localise("no_working_proxies"))
                    log("[BooruSearch] –†–∞–±–æ—á–∏–µ –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    
            except Exception as e:
                error_msg = str(e)
                BulletinHelper.show_error(localise("proxy_update_error").format(error=error_msg))
                log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –ø—Ä–æ–∫—Å–∏: {e}")
        
        threading.Thread(target=update_proxies_background, daemon=True).start()
    
    def _dismiss_dialog(self):
        pass

    def on_setting_changed(self, key, value):
        try:
            if key == "use_proxy" and bool(value):
                self.update_proxy_list()
        except Exception as e:
            log(f"[BooruSearch] on_setting_changed error: {e}")

    def _build_caption_text(self, requested_tags_str: str, post_tags: str, image_url: str, rating: str = '') -> str:
        try:
            from java.util import Locale as _Loc
            _lang = _Loc.getDefault().getLanguage()
        except Exception:
            _lang = "ru"

        nsfw = int(self.get_setting("theme_style", 0)) == 1

        if _lang.startswith("ru"):
            header = "*–ù–∞–π–¥–µ–Ω –ø–æ—Å—Ç!*"
            req_label = "*–ó–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–µ —Ç–µ–≥–∏:*"
            tags_label = "*–¢–µ–≥–∏ –≤ –ø–æ—Å—Ç–µ:*"
            link_label = "*–°—Å—ã–ª–∫–∞:*"
            open_text = "–û—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
        else:
            header = "*Post found!*"
            req_label = "*Requested tags:*"
            tags_label = "*Post tags:*"
            link_label = "*Link:*"
            open_text = "Open image"

        if nsfw:
            emo_header = localise("emoji_header_nso")
            emo_req = localise("emoji_req_nso")
            emo_tags = localise("emoji_tags_nso")
            emo_link = localise("emoji_link_nso")
        else:
            emo_header = localise("emoji_header_normal")
            emo_req = localise("emoji_req_normal")
            emo_tags = localise("emoji_tags_normal")
            emo_link = localise("emoji_link_normal")

        lines = []
        lines.append(f"{emo_header} | {header}")

        if self.get_setting("show_requested_tags", True) and requested_tags_str:
            code_req = self._md_code(requested_tags_str)
            lines.append(f"{emo_req} | {req_label} `{code_req}`")

        if self.get_setting("show_post_tags", True) and post_tags:
            code_tags = self._md_code(post_tags)
            lines.append(f"{emo_tags} | {tags_label} `{code_tags}`")
        
        if rating:
            if _lang.startswith("ru"):
                rating_label = "*–†–µ–π—Ç–∏–Ω–≥:*"
            else:
                rating_label = "*Rating:*"
            if nsfw:
                rating_emoji = "[üíî](5258354685563129815)"
            else:
                rating_emoji = "[üõ°](5276262671962892944)"
            
            lines.append(f"{rating_emoji} | {rating_label} `{rating}`")

        if self.get_setting("show_image_link", True) and image_url:
            lines.append(f"{emo_link} | {link_label} [{open_text}]({image_url})")

        return "\n".join(lines)

    def _md_code(self, s: str) -> str:
        try:
            return s.replace('`', r'\`')
        except Exception:
            return s

    def _download_media(self, url: str) -> tuple:
        try:
            ext = os.path.splitext(url.split('?')[0])[1].lower()
            is_image_ext = ext in ('.jpg', '.jpeg', '.webp','.png')
            filename = f"rule34_{uuid.uuid4().hex}{ext if ext else ''}"
            data_dir = ApplicationLoader.getFilesDirFixed()
            local_path = os.path.join(str(data_dir), filename)

            def do_request(session_proxies=None):
                with requests.get(url, stream=True, timeout=20, proxies=session_proxies) as r:
                    r.raise_for_status()
                    with open(local_path, 'wb') as f:
                        for chunk in r.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)

            try:
                do_request()
            except Exception:
                if self.get_setting("use_proxy", True):
                    proxy = get_working_proxy()
                    if proxy:
                        do_request(proxy)
                    else:
                        raise
                else:
                    raise

            if not ext:
                ctype = mimetypes.guess_type(local_path)[0] or ''
                is_image_ext = ctype.startswith('image/')

            return local_path, is_image_ext
        except Exception as e:
            raise e
